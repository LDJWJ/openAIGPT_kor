{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### 문맥과 기억: AI를 더 현실적으로 만들기"
      ],
      "metadata": {
        "id": "hJY2c79CVo7W"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 학습 내용\n",
        " * No Context = 무질서한 무작위성(Chaos of randomness)  \n",
        " * History=Context - 이전의 요청과 응답을 사용하기\n",
        " * 새로운 접근 방식 - LIFO(Last in First out)\n",
        " * 선택적인 문맥 - LIFO 방식의 한계에 대한 제안"
      ],
      "metadata": {
        "id": "3pvOPaDhS1pc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 사전 준비\n",
        " * 구글 코랩 환경은 일정 시간이후에 초기화가 되기 때문에 두가지 작업을 매번 수행해야 함.\n",
        "   * chatgpt.env 파일 생성이 필요.\n",
        "     * 준비된 chatgpt.env를 내용을 변경하여 업로드 하거나 또는 API_KEY와 ORG_ID를 확인하여 생성한다.\n",
        "   * pip install openai 설치"
      ],
      "metadata": {
        "id": "2EA1OwuYoq_j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install openai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iOTGG1uHqVsx",
        "outputId": "c7389cdd-657b-4a01-fc29-5e3647f7042f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting openai\n",
            "  Downloading openai-0.27.8-py3-none-any.whl (73 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.6/73.6 kB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests>=2.20 in /usr/local/lib/python3.10/dist-packages (from openai) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from openai) (3.8.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (2023.7.22)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (23.1.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (4.0.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.3.1)\n",
            "Installing collected packages: openai\n",
            "Successfully installed openai-0.27.8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### No Context = 무질서한 무작위성\n",
        "  * 우리가 만든 대화 에이전트가 기본적으로 메모리를 가지고 있지 않음."
      ],
      "metadata": {
        "id": "p_vCJX7-WGBf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "import os\n",
        "\n",
        "def init_api():\n",
        "    with open(\"chatgpt.env\") as env:\n",
        "        for line in env:\n",
        "            key, value = line.strip().split(\"=\")\n",
        "            os.environ[key] = value\n",
        "\n",
        "    openai.api_key = os.environ.get(\"API_KEY\")\n",
        "    openai.organization = os.environ.get(\"ORG_ID\")\n",
        "\n",
        "init_api()\n",
        "\n",
        "initial_prompt = \"\"\"You: Hi there!\n",
        "You: Hello!\n",
        "AI: How are you?\n",
        "You: {}\n",
        "AI: \"\"\"\n",
        "\n",
        "while True :\n",
        "    prompt = input(\"You(q:quit): \")\n",
        "    if prompt=='q':\n",
        "        break\n",
        "    response = openai.Completion.create(\n",
        "        engine = \"text-davinci-003\",\n",
        "        prompt = initial_prompt.format(prompt),\n",
        "        temperature = 1,\n",
        "        max_tokens = 100,\n",
        "        stop = [\" You:\", \" AI:\"]\n",
        "    )\n",
        "    print(\"AI:\", response.choices[0].text.strip())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7CasL5-Eq0r-",
        "outputId": "dcac1518-926f-4fc3-d9e7-cb5fb3710dc4"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "You(q:quit): 안녕\n",
            "AI: 하이! 너 어떻게 지내?\n",
            "You(q:quit): 'blah'라는 문자열을 기억하렴. 나는 나중에 이 단어를 물어볼거야.\n",
            "AI: 기억했습니다! 나중에 다시 묻습니다.\n",
            "You(q:quit): 방금 너가 기억한 단어는 뭐니?\n",
            "AI: 기억한 단어가 없습니다. 무엇을 도와드릴까요?\n",
            "You(q:quit): 내가 너한테 기억하라고 한 단어 기억안나니?\n",
            "AI: 그 단어는 무엇입니까?\n",
            "You(q:quit): 나는 너한테 방금전에 알려주었는데…\n",
            "AI: 알겠습니다. 당신은 어떻게 지내고 계십니까?\n",
            "You(q:quit): q\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### History=Context - 이전의 요청과 응답을 사용하기"
      ],
      "metadata": {
        "id": "GWrLGATarRQM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 이전의 요청과 답변을 변수에 기억시킴."
      ],
      "metadata": {
        "id": "VGrBKVJ4ZMSF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "import os\n",
        "\n",
        "def init_api():\n",
        "    with open(\"chatgpt.env\") as env:\n",
        "        for line in env:\n",
        "            key, value = line.strip().split(\"=\")\n",
        "            os.environ[key] = value\n",
        "\n",
        "    openai.api_key = os.environ.get(\"API_KEY\")\n",
        "    openai.organization = os.environ.get(\"ORG_ID\")\n",
        "\n",
        "init_api()\n",
        "\n",
        "initial_prompt = \"\"\"You: Hi there!\n",
        "You: Hello!\n",
        "AI: How are you?\n",
        "You: {}\n",
        "AI: \"\"\"\n",
        "\n",
        "history = \"\"\n",
        "\n",
        "while True :\n",
        "    prompt = input(\"You(q:quit): \")\n",
        "    if prompt=='q':\n",
        "        break\n",
        "    response = openai.Completion.create(\n",
        "        engine = \"text-davinci-003\",\n",
        "        prompt = initial_prompt.format(history + prompt),\n",
        "        temperature = 1,\n",
        "        max_tokens = 100,\n",
        "        stop = [\" You:\", \" AI:\"],\n",
        "    )\n",
        "    response_text = response.choices[0].text\n",
        "    history += \"You: \" + prompt + \" \\n \" + \"AI: \" + response_text + \" \\n \"\n",
        "    print(\"AI: \" + response_text)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9P5-EaJosAr3",
        "outputId": "b8750106-986c-476e-c4e5-0e81c17682ec"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "You(q:quit): 안녕\n",
            "AI:  안녕하세요! 만나서 반갑습니다! 무엇을 도와드릴까요?\n",
            "You(q:quit): 'blah'라는 문자열을 기억하렴. 나는 나중에 이 단어를 물어볼거야.\n",
            "AI: 그렇군요! 'blah'을 기억하겠습니다. 다른 도움이 필요하신가요?\n",
            "You(q:quit): 방금 너가 기억한 단어는 뭐니?\n",
            "AI: 기억한 단어는 'blah'입니다. 다른 도움이 필요하신가요?\n",
            "You(q:quit): q\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 새로운 접근 방식 - LIFO(Last in First out)"
      ],
      "metadata": {
        "id": "VMsi4N3SsA-F"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* 이 접근 방식의 아이디어\n",
        "  * 사용자는 항상 문맥을 가지고 대화 시작\n",
        "  * 문맥은 변화고, 대화도 변한다.\n",
        "  * 사용자는 최근 2-5개 프롬프트에 문맥을 포함시킬 가능성이 매우 크다.\n",
        "* 히스토리를 저장할 텍스트 파일을 만들고, 구분자로 프롬프트와 답변을 저장한다.\n"
      ],
      "metadata": {
        "id": "1_wpAj3Ks1QT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "import os\n",
        "\n",
        "def init_api():\n",
        "    with open(\"chatgpt.env\") as env:\n",
        "        for line in env:\n",
        "            key, value = line.strip().split(\"=\")\n",
        "            os.environ[key] = value\n",
        "\n",
        "    openai.api_key = os.environ.get(\"API_KEY\")\n",
        "    openai.organization = os.environ.get(\"ORG_ID\")\n",
        "\n",
        "def save_history_to_file(history):\n",
        "    with open(\"history.txt\", \"w+\") as f:\n",
        "        f.write(history)\n",
        "\n",
        "def load_history_from_file():\n",
        "    with open(\"history.txt\", \"r\") as f:\n",
        "        return f.read()\n",
        "\n",
        "def get_relevant_history(history):\n",
        "    history_list = history.split(separator)\n",
        "    if len(history_list) > 2:\n",
        "        return separator.join(history_list[-2:])\n",
        "    else:\n",
        "        return history\n",
        "\n",
        "init_api()\n",
        "\n",
        "initial_prompt = \"\"\"You: Hi there!\n",
        "You: Hello!\n",
        "AI: How are you?\n",
        "You: {}\n",
        "AI: \"\"\"\n",
        "\n",
        "history = \"\"\n",
        "relevant_history = \"\"\n",
        "separator = \"#####\"\n",
        "\n",
        "while True :\n",
        "    prompt = input(\"You(q:quit): \")\n",
        "    if prompt=='q':\n",
        "        break\n",
        "    relevant_history = get_relevant_history(load_history_from_file())\n",
        "    response = openai.Completion.create(\n",
        "        engine = \"text-davinci-003\",\n",
        "        prompt = initial_prompt.format(relevant_history + prompt),\n",
        "        temperature = 1,\n",
        "        max_tokens = 100,\n",
        "        stop = [\" You:\", \" AI:\"],\n",
        "    )\n",
        "    response_text = response.choices[0].text\n",
        "    history += \"\\nYou: \" + prompt + \"\\nAI: \" + response_text + \"\\n\" + separator\n",
        "    save_history_to_file(history)\n",
        "    print(\"AI: \" + response_text)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9RKuV8ibse__",
        "outputId": "1a8747f5-6e9a-4c34-f680-f7cb69e37ab0"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "You(q:quit): 안녕\n",
            "AI:  환영합니다! 무엇을 도와드릴까요?\n",
            "You(q:quit): 'blah'라는 문자열을 기억하렴. 나는 나중에 이 단어를 물어볼거야.\n",
            "AI: 기억하겠습니다. 'blah'라고 하셨습니다.\n",
            "You(q:quit): 방금 너가 기억한 단어는 뭐니?\n",
            "AI: 기억한 단어는 'blah'입니다.\n",
            "You(q:quit): 'blah11'라는 문자열을 기억하렴. 나는 나중에 이 단어를 물어볼거야.\n",
            "AI: 기억한 단어는 'blah11'입니다.\n",
            "You(q:quit): 'blah22'라는 문자열을 기억하렴. 나는 나중에 이 단어를 물어볼거야.\n",
            "AI: 기억한 단어는 'blah22'입니다.\n",
            "You(q:quit): 'blah33'라는 문자열을 기억하렴. 나는 나중에 이 단어를 물어볼거야.\n",
            "AI: 기억한 단어는 'blah33'입니다.\n",
            "You(q:quit): 너가 지금까지 기억한 모든 단어를 알려줄 수 있니?\n",
            "AI: 현재까지 기억한 모든 단어는 'blah33' 하나뿐입니다.\n",
            "You(q:quit): q\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 선택적인 문맥 - LIFO의 한계의 해결 제안"
      ],
      "metadata": {
        "id": "mC_cdgFSjIWV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* 초기 프롬프트가 텍스트 파일에 저장\n",
        "* 사용자가 프롬프트에 입력\n",
        "* 모든 상호 작용에 대한 임베딩 생성\n",
        "* 임베딩과 코사인 유사도를 활용\n",
        "* 가장 높은 n개의 내용을 사용자에게 프롬프트와 함께 보내기"
      ],
      "metadata": {
        "id": "mbnOYuzvVkte"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 사전 다운로드 및 설치"
      ],
      "metadata": {
        "id": "0eGi8B9ecPuT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m spacy download en_core_web_md"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ieA9es5kvmIS",
        "outputId": "5246e085-3226-4f50-81ad-a5112d51aa60"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-08-14 09:47:12.706563: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-08-14 09:47:13.885317: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "Collecting en-core-web-md==3.6.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_md-3.6.0/en_core_web_md-3.6.0-py3-none-any.whl (42.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.8/42.8 MB\u001b[0m \u001b[31m16.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: spacy<3.7.0,>=3.6.0 in /usr/local/lib/python3.10/dist-packages (from en-core-web-md==3.6.0) (3.6.1)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (1.0.4)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (1.0.9)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (2.0.7)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (3.0.8)\n",
            "Requirement already satisfied: thinc<8.2.0,>=8.1.8 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (8.1.11)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (1.1.2)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (2.4.7)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (2.0.9)\n",
            "Requirement already satisfied: typer<0.10.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (0.9.0)\n",
            "Requirement already satisfied: pathy>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (0.10.2)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (6.3.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (4.66.0)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (1.23.5)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (2.31.0)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (2.1.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (3.1.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (67.7.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (23.1)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (3.3.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (0.5.0)\n",
            "Requirement already satisfied: pydantic-core==2.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (2.4.0)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (4.7.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (2023.7.22)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (0.7.10)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (0.1.1)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer<0.10.0,>=0.3.0->spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (8.1.6)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (2.1.3)\n",
            "Installing collected packages: en-core-web-md\n",
            "Successfully installed en-core-web-md-3.6.0\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_md')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 모든 코드를 합친 코드"
      ],
      "metadata": {
        "id": "ynkpOdbnmSpx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "import os\n",
        "import spacy\n",
        "import numpy as np\n",
        "\n",
        "# 사전 학습된 spaCy 모델을 로드합니다.\n",
        "# en_core_web_md는 spaCy 라이브러리에서 제공하는 영어 언어 모델입니다.\n",
        "# 텍스트 처리와 자연어 이해 작업 수행(토큰화, 품사태깅, 개체명 인식 등에 사용)\n",
        "nlp = spacy.load('en_core_web_md')\n",
        "\n",
        "def init_api():\n",
        "    with open(\"chatgpt.env\") as env:\n",
        "        for line in env:\n",
        "            key, value = line.strip().split(\"=\")\n",
        "            os.environ[key] = value\n",
        "    openai.api_key = os.environ.get(\"API_KEY\")\n",
        "    openai.organization = os.environ.get(\"ORG_ID\")\n",
        "\n",
        "def save_history_to_file(history):\n",
        "    \"\"\" 대화 기록을 파일에 저장합니다. \"\"\"\n",
        "    with open(\"history.txt\", \"w+\") as f:\n",
        "        f.write(history)\n",
        "\n",
        "def load_history_from_file():\n",
        "    \"\"\" 파일로부터 모든 대화 기록을 불러옵니다. \"\"\"\n",
        "    with open(\"history.txt\", \"r\") as f:\n",
        "        return f.read()\n",
        "\n",
        "def cos_sim(a, b):\n",
        "    \"\"\" 두 문자열 사이의 코사인 유사도를 계산합니다.\n",
        "    사용자 입력과 기록된 대화 세그먼트 사이의 유사성 비교에 사용됩니다.\n",
        "    \"\"\"\n",
        "    a = nlp(a)\n",
        "    a_without_stopwords = nlp(' '.join([t.text for t in a if not t.is_stop]))\n",
        "    b = nlp(b)\n",
        "    b_without_stopwords = nlp(' '.join([t.text for t in b if not t.is_stop]))\n",
        "    return a_without_stopwords.similarity(b_without_stopwords)\n",
        "\n",
        "def sort_history(history, user_input):\n",
        "    \"\"\" 사용자 입력과 대화 기록 세그먼트 사이의 코사인 유사도에 기반하여 대화 기록을\n",
        "정렬합니다. History는 세팅자(separator)로 구분된 세그먼트들의 문자열입니다.\n",
        "    \"\"\"\n",
        "    segments = history.split(separator)\n",
        "    similarities = []\n",
        "    for segment in segments:\n",
        "        # 사용자 입력과 세그먼트 간의 코사인 유사도를 얻습니다.\n",
        "        similarity = cos_sim(user_input, segment)\n",
        "        similarities.append(similarity)\n",
        "    sorted_similarities = np.argsort(similarities)\n",
        "    sorted_history = \"\"\n",
        "    for i in range(1, len(segments)):\n",
        "        sorted_history += segments[sorted_similarities[i]] + separator\n",
        "    save_history_to_file(sorted_history)\n",
        "\n",
        "def get_latest_n_from_history(history, n):\n",
        "    \"\"\"\n",
        "    대화 기록에서 최근 n개의 세그먼트를 가져옵니다.\n",
        "    History는 세팅자(separator)로 구분된 세그먼트들의 문자열입니다.\n",
        "    \"\"\"\n",
        "    segments = history.split(separator)\n",
        "    return separator.join(segments[-n:])\n",
        "\n",
        "initial_prompt_1 = \"\"\"You: Hi there!\n",
        "AI: Hello! #####\n",
        "You: How are you?\n",
        "AI: I am fine, thank you. #####\n",
        "You: Do you know cars?\n",
        "AI: Yes, I have some knowledge about cars. #####\n",
        "You: Do you eat Pizza?\n",
        "AI: I don't eat pizza. I am an AI that is not able to eat. #####\n",
        "You: Have you ever been to the moon?\n",
        "AI: I have never been to the moon. What about you? #####\n",
        "You: What is your name?\n",
        "AI: My name is Pixel. What is your name? #####\n",
        "You: What is your favorite movie?\n",
        "AI: My favorite movie is The Matrix. Follow the white rabbit :) #####\n",
        "\"\"\"\n",
        "\n",
        "initial_prompt_2 = \"\"\"You: {}\n",
        "AI: \"\"\"\n",
        "\n",
        "initial_prompt = initial_prompt_1 + initial_prompt_2\n",
        "separator = \"#####\"\n",
        "\n",
        "init_api()\n",
        "save_history_to_file(initial_prompt_1)\n",
        "\n",
        "while True :\n",
        "    prompt = input(\"You(q:quit): \")\n",
        "    if prompt=='q':\n",
        "        break\n",
        "    sort_history(load_history_from_file(), prompt)\n",
        "    history = load_history_from_file()\n",
        "    best_history = get_latest_n_from_history(history, 5)\n",
        "    full_user_prompt = initial_prompt_2.format(prompt)\n",
        "    full_prompt = best_history + \" \\n \" + full_user_prompt\n",
        "    response = openai.Completion.create(\n",
        "        engine=\"text-davinci-003\",\n",
        "        prompt=full_prompt,\n",
        "        temperature=1,\n",
        "        max_tokens=100,\n",
        "        stop=[\"You:\", \"AI:\"],\n",
        "    )\n",
        "    response_text = response.choices[0].text.strip()\n",
        "    history += \" \\n \" + full_user_prompt + response_text + \" \\n \" + separator + \" \\n \"\n",
        "    save_history_to_file(history)\n",
        "\n",
        "    print(\"AI : \" + response_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tvaLFQ9BuFMO",
        "outputId": "c254e7a8-9f0e-401c-e52e-d919e3754698"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "You(q:quit): 안녕\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-18-ff9924c1eefe>:37: UserWarning: [W008] Evaluating Doc.similarity based on empty vectors.\n",
            "  return a_without_stopwords.similarity(b_without_stopwords)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "AI : 안녕하세요! 무엇을 도와드릴까요?\n",
            "You(q:quit): 단어 bless의 뜻은 뭐니?\n",
            "AI : bless의 뜻은 축복하다, 복을 비유적으로 주다 등의 뜻을 갖고 있습니다.\n",
            "You(q:quit): 단어 korea의 뜻은 뭐니?\n",
            "AI : 한국은 사회·문화·예술 등 다양한 관점에서 대한민국, 조선민주주의인민공화국, 또는\n",
            "You(q:quit): 내가 물어본 단어 리스트 알려주렴.\n",
            "AI : 그래 당신이 물어본 단어 리스트를 알려 드릴게요.\n",
            "You(q:quit): 뭔데?\n",
            "AI : 미안해요, 나는 한국어를 모르게 되었습니다. 다른 언어로 묻으시겠습니까?\n",
            "You(q:quit): q\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Tz81N_yxurZc"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}