{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## 05. GPT 모델로 텍스트 편집하기"
      ],
      "metadata": {
        "id": "dpdCBDmFHfqq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 학습 내용\n",
        "* 실습: 텍스트 번역하기\n",
        "* 'instruction'은 필수! 'input'은 선택!\n",
        "* Completions 엔드포인트를 사용한 수정\n",
        "* 출력 포맷 정하기\n",
        "* 창의성 vs. 잘 정의된 답\n",
        "* 여러 결과에 대한 편집 생성하기"
      ],
      "metadata": {
        "id": "JD9pte-EHswd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 사전 준비\n",
        " * 구글 코랩 환경은 일정 시간이후에 초기화가 되기 때문에 두가지 작업을 매번 수행해야 함.\n",
        "   * chatgpt.env 파일 생성이 필요.\n",
        "     * 준비된 chatgpt.env를 내용을 변경하여 업로드 하거나 또는 API_KEY와 ORG_ID를 확인하여 생성한다.\n",
        "   * pip install openai 설치"
      ],
      "metadata": {
        "id": "Mv-r5TdWJrVb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### openai 설치"
      ],
      "metadata": {
        "id": "jQ5fkV_oJsjx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install openai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "64_8VBlDJuhT",
        "outputId": "466377d0-c18e-45b4-cbe8-2d41563b66e0"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting openai\n",
            "  Downloading openai-1.3.7-py3-none-any.whl (221 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/221.4 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.0/221.4 kB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.4/221.4 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━\u001b[0m \u001b[32m215.0/221.4 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m221.4/221.4 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: anyio<4,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
            "Collecting httpx<1,>=0.23.0 (from openai)\n",
            "  Downloading httpx-0.25.2-py3-none-any.whl (74 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.0/75.0 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (1.10.13)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.0)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.5 in /usr/local/lib/python3.10/dist-packages (from openai) (4.5.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<4,>=3.5.0->openai) (3.6)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<4,>=3.5.0->openai) (1.2.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2023.11.17)\n",
            "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai)\n",
            "  Downloading httpcore-1.0.2-py3-none-any.whl (76 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.9/76.9 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: h11, httpcore, httpx, openai\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "llmx 0.0.15a0 requires cohere, which is not installed.\n",
            "llmx 0.0.15a0 requires tiktoken, which is not installed.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed h11-0.14.0 httpcore-1.0.2 httpx-0.25.2 openai-1.3.7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 실습 : 텍스트 번역하기\n",
        " * 독일어를 영어로 번역"
      ],
      "metadata": {
        "id": "L83G3fjpH7-Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from openai import OpenAI\n",
        "import os\n",
        "\n",
        "\n",
        "def init_api():\n",
        "    with open(\"chatgpt.env\") as env:\n",
        "       for line in env:\n",
        "           key, value = line.strip().split(\"=\")\n",
        "           os.environ[key] = value\n",
        "\n",
        "init_api()\n",
        "\n",
        "client = OpenAI(api_key  = os.environ.get(\"API_KEY\"),\n",
        "                organization  = os.environ.get(\"ORG_ID\"))\n",
        "\n",
        "next = client.chat.completions.create(\n",
        "  model=\"gpt-3.5-turbo\",\n",
        "  messages=[\n",
        "    {\n",
        "      \"role\": \"system\",\n",
        "      \"content\": \"Translate to English\"\n",
        "    },\n",
        "    {\n",
        "      \"role\": \"user\",\n",
        "      \"content\": \"Hallo Welt\"\n",
        "    }\n",
        "  ],\n",
        "  temperature=0,\n",
        "  max_tokens=256,\n",
        "  top_p=1,\n",
        "  frequency_penalty=0,\n",
        "  presence_penalty=0\n",
        ")\n",
        "\n",
        "print(next)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ixrrT2PoQHE7",
        "outputId": "65cb7967-b2fc-4b49-e14a-aebc401c7301"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ChatCompletion(id='chatcmpl-8RFEp5VUT0MAcDCsldcWOZNaKx8r5', choices=[Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Hello world', role='assistant', function_call=None, tool_calls=None))], created=1701504123, model='gpt-3.5-turbo-0613', object='chat.completion', system_fingerprint=None, usage=CompletionUsage(completion_tokens=2, prompt_tokens=16, total_tokens=18))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "next"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-yDLGvi_Qqn2",
        "outputId": "24dc1982-ea09-474e-f8fa-f2d36c81b31c"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ChatCompletion(id='chatcmpl-8RFEp5VUT0MAcDCsldcWOZNaKx8r5', choices=[Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Hello world', role='assistant', function_call=None, tool_calls=None))], created=1701504123, model='gpt-3.5-turbo-0613', object='chat.completion', system_fingerprint=None, usage=CompletionUsage(completion_tokens=2, prompt_tokens=16, total_tokens=18))"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 초기 가이드 제공하는 시스템 메시지(System), 사용자 입력(User)"
      ],
      "metadata": {
        "id": "23F7uuwMJy03"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* 코드에서 system은 모델의 역할에 대한 초기 가이드를 입력합니다. USER 메시지 이를 수행하려고 하는 메시지를 입력합니다. Playground에서 제공하는 몇 가지 예를 들면 다음과 같습니다."
      ],
      "metadata": {
        "id": "NjDu2_-RLqzw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from openai import OpenAI\n",
        "\n",
        "def init_api():\n",
        "    with open(\"chatgpt.env\") as env:\n",
        "       for line in env:\n",
        "           key, value = line.strip().split(\"=\")\n",
        "           os.environ[key] = value\n",
        "\n",
        "init_api()\n",
        "\n",
        "client = OpenAI(api_key  = os.environ.get(\"API_KEY\"),\n",
        "                organization  = os.environ.get(\"ORG_ID\"))\n",
        "\n",
        "\n",
        "next = client.chat.completions.create(\n",
        "  model=\"gpt-3.5-turbo\",\n",
        "  messages=[\n",
        "    {\n",
        "      \"role\": \"system\",\n",
        "      \"content\": \"Translate to English\"\n",
        "    },\n",
        "    {\n",
        "      \"role\": \"user\",\n",
        "      \"content\": \"Hallo Welt\"\n",
        "    }\n",
        "  ]\n",
        ")\n",
        "\n",
        "print(next)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ApgTnq6rLvP_",
        "outputId": "5a350cd2-09d1-4391-b198-872a8a936658"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ChatCompletion(id='chatcmpl-8REUT0mEnWPyRcfpg525AkAlyIzrV', choices=[Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Hello world', role='assistant', function_call=None, tool_calls=None))], created=1701501249, model='gpt-3.5-turbo-0613', object='chat.completion', system_fingerprint=None, usage=CompletionUsage(completion_tokens=2, prompt_tokens=16, total_tokens=18))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 다국어로 번역 작업 요청해 보기"
      ],
      "metadata": {
        "id": "cZO_7fTzL6aZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import openai\n",
        "\n",
        "from openai import OpenAI\n",
        "\n",
        "def init_api():\n",
        "    with open(\"chatgpt.env\") as env:\n",
        "       for line in env:\n",
        "           key, value = line.strip().split(\"=\")\n",
        "           os.environ[key] = value\n",
        "\n",
        "init_api()\n",
        "\n",
        "client = OpenAI(api_key  = os.environ.get(\"API_KEY\"),\n",
        "                organization  = os.environ.get(\"ORG_ID\"))\n",
        "\n",
        "\n",
        "next = client.chat.completions.create(\n",
        "  model=\"gpt-3.5-turbo\",\n",
        "  messages=[\n",
        "    {\n",
        "      \"role\": \"system\",\n",
        "      \"content\": \"Translate from English to French, Arabic, and Spanish.\"\n",
        "    },\n",
        "    {\n",
        "      \"role\": \"user\",\n",
        "      \"content\": \"The cat sat on the mat.\"\n",
        "    }\n",
        "  ]\n",
        ")\n",
        "\n",
        "print(next.choices[0].message.content)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iWafU_KLN4a4",
        "outputId": "5e6b767d-b6f1-4d97-9a96-c54fa1cbccbe"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Le chat était assis sur le tapis. (French)\n",
            "القطة جلست على البساط. (Arabic)\n",
            "El gato se sentó en la alfombra. (Spanish)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(next.choices[0].message.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bm0Yj3Z2YUBR",
        "outputId": "ebca4887-2fee-4215-db9f-ad9110ac7b24"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "French: Le chat était assis sur le tapis.\n",
            "Arabic: جلس القط على السجادة.\n",
            "Spanish: El gato se sentó en el tapete.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 다른 예제 확인해 보기"
      ],
      "metadata": {
        "id": "fWLWLFYaN4vn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 텍스트 완성을 위한 Edit 엔드 포인트 사용"
      ],
      "metadata": {
        "id": "n_1ch-umOb16"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import openai\n",
        "\n",
        "from openai import OpenAI\n",
        "\n",
        "def init_api():\n",
        "    with open(\"chatgpt.env\") as env:\n",
        "       for line in env:\n",
        "           key, value = line.strip().split(\"=\")\n",
        "           os.environ[key] = value\n",
        "\n",
        "init_api()\n",
        "\n",
        "client = OpenAI(api_key  = os.environ.get(\"API_KEY\"),\n",
        "                organization  = os.environ.get(\"ORG_ID\"))\n",
        "\n",
        "\n",
        "next = client.chat.completions.create(\n",
        "  model=\"gpt-3.5-turbo\",\n",
        "  messages=[\n",
        "    {\n",
        "      \"role\": \"system\",\n",
        "      \"content\": \"Complete the story\"\n",
        "    },\n",
        "    {\n",
        "      \"role\": \"user\",\n",
        "      \"content\": \"Once upon a time\"\n",
        "    }\n",
        "  ]\n",
        ")\n",
        "\n",
        "print(next.choices[0].message.content)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OPNboFqhZZK6",
        "outputId": "79170412-2396-402a-8873-b1e9c1b9c728"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "in a small village nestled in the heart of a lush green valley, there lived a young girl named Lily. Lily was known for her curiosity and adventurous spirit. She had always dreamed of exploring the world beyond the village and discovering hidden treasures.\n",
            "\n",
            "One sunny morning, as Lily was walking by the village square, she noticed an old map lying on the ground. Intrigued, she picked it up and examined it closely. It appeared to be a treasure map, with intricate drawings of mountains, rivers, and forests. Lily's heart raced with excitement as she realized that this might be the opportunity she had been waiting for.\n",
            "\n",
            "With the map in hand, Lily rushed back home and began studying it with great devotion. She deciphered clues and marked the locations on her own handmade map. It became clear that the hidden treasure was located deep within the Enchanted Forest, a mystical place rumored to hold unimaginable wonders.\n",
            "\n",
            "Unfazed by the dangers that lay ahead, Lily embarked on her journey the very next morning. Carrying only a small knapsack filled with provisions and her trusty compass, she bravely ventured into the dense forest. As she moved deeper into the woods, mysterious creatures whispered through the trees, making her feel both fear and excitement.\n",
            "\n",
            "Days turned into weeks, but Lily didn't give up. She followed the map with determination, navigating through treacherous terrains and overcoming numerous obstacles. The forest seemed to come alive with magical creatures trying to deter her from her path, but Lily's determination never wavered.\n",
            "\n",
            "Finally, after what felt like an eternity, Lily stood before a massive ancient tree. Its gnarled branches reached towards the sky, and a sense of mystery surrounded it. According to the map, the treasure was hidden somewhere within its hollow trunk.\n",
            "\n",
            "With trembling hands, Lily approached the tree and pushed aside the overgrown foliage. Inside, she found not gold or jewels but a small, ancient book. It seemed unremarkable at first, but as she opened it, she realized that it contained the most extraordinary tales and secrets of the Enchanted Forest.\n",
            "\n",
            "Lily spent the following days absorbed in the knowledge and stories held within that magical book. She discovered the healing powers of certain plants and learned the language of the forest creatures. She became a guardian of nature and eventually returned to her village, sharing her newfound wisdom with eager villagers.\n",
            "\n",
            "The village thrived under Lily's guidance. The people learned to respect and cherish the woods that surrounded them and became stewards of the land. The once-barren fields bloomed with life, and the animals found sanctuary in the village's embrace.\n",
            "\n",
            "Lily's journey not only brought her the treasure she sought but also enriched the lives of those around her. Her adventure had taught her that true wealth lies not in material possessions but in the harmony we create with the world around us.\n",
            "\n",
            "And so, the tale of Lily, the young girl who found treasure beyond her wildest dreams, became a legend told by generations to come, inspiring others to explore, discover, and protect the wonders of the world.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 코드에 주석을 추가하기\n",
        " * Golang 코드의 주석 추가"
      ],
      "metadata": {
        "id": "wEqhHlc0Oqq6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import openai\n",
        "\n",
        "from openai import OpenAI\n",
        "\n",
        "def init_api():\n",
        "    with open(\"chatgpt.env\") as env:\n",
        "       for line in env:\n",
        "           key, value = line.strip().split(\"=\")\n",
        "           os.environ[key] = value\n",
        "\n",
        "init_api()\n",
        "\n",
        "client = OpenAI(api_key  = os.environ.get(\"API_KEY\"),\n",
        "                organization  = os.environ.get(\"ORG_ID\"))\n",
        "\n",
        "\n",
        "code = \"\"\"\n",
        "package main\n",
        "\n",
        "import (\n",
        "   \"io/ioutil\"\n",
        "   \"log\"\n",
        "   \"net/http\"\n",
        ")\n",
        "\n",
        "func main() {\n",
        "   resp, err := http.Get(\"https://website.com\")\n",
        "   if err != nil {\n",
        "      log.Fatalln(err)\n",
        "   }\n",
        "\n",
        "   body, err := ioutil.ReadAll(resp.Body)\n",
        "   if err != nil {\n",
        "      log.Fatalln(err)\n",
        "   }\n",
        "\n",
        "   sb := string(body)\n",
        "   log.Printf(sb)\n",
        "}\n",
        "  \"\"\"\n",
        "\n",
        "next = client.chat.completions.create(\n",
        "  model=\"gpt-3.5-turbo\",\n",
        "  messages=[\n",
        "    {\n",
        "      \"role\": \"system\",\n",
        "      \"content\": \"Golang code의 주석을 한글로 달아주세요.\"\n",
        "    },\n",
        "    {\n",
        "      \"role\": \"user\",\n",
        "      \"content\": code\n",
        "    }\n",
        "  ]\n",
        ")\n",
        "\n",
        "print(\"##### Golang code 설명 #####\")\n",
        "print(next) # 응답 결과의 text 가져오기\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DNtXPtp1an-Z",
        "outputId": "1a0c7bc2-58e6-47fc-9ebd-6d75f382f36f"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "##### Golang code 설명 #####\n",
            "ChatCompletion(id='chatcmpl-8REjqBXP7nc9X7BNhrFsGC2KO2iK0', choices=[Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='// main 패키지 선언\\npackage main\\n\\n// 필요한 패키지 import\\nimport (\\n   \"io/ioutil\" // 파일 및 디렉토리 읽기를 위한 패키지\\n   \"log\" // 로그 출력을 위한 패키지\\n   \"net/http\" // HTTP 요청 및 응답을 위한 패키지\\n)\\n\\n// 메인 함수\\nfunc main() {\\n   resp, err := http.Get(\"https://website.com\") // 주어진 URL로 GET 요청을 보내고 응답을 가져옴\\n   if err != nil {\\n      log.Fatalln(err) // 에러가 발생한 경우 에러를 출력하고 프로그램 종료\\n   }\\n\\n   body, err := ioutil.ReadAll(resp.Body) // 응답 바디의 내용을 읽어옴\\n   if err != nil {\\n      log.Fatalln(err) // 에러가 발생한 경우 에러를 출력하고 프로그램 종료\\n   }\\n\\n   sb := string(body) // 바이트 슬라이스를 문자열로 변환\\n   log.Printf(sb) // 응답 바디를 로그로 출력\\n}', role='assistant', function_call=None, tool_calls=None))], created=1701502202, model='gpt-3.5-turbo-0613', object='chat.completion', system_fingerprint=None, usage=CompletionUsage(completion_tokens=285, prompt_tokens=118, total_tokens=403))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(next.choices[0].message.content) # 응답 결과의 text 가져오기"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rj9vUyIyOvNI",
        "outputId": "72e24fbd-9938-46ed-c4fe-385ab2ba225b"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "// main 패키지 선언\n",
            "package main\n",
            "\n",
            "// 필요한 패키지 import\n",
            "import (\n",
            "   \"io/ioutil\" // 파일 및 디렉토리 읽기를 위한 패키지\n",
            "   \"log\" // 로그 출력을 위한 패키지\n",
            "   \"net/http\" // HTTP 요청 및 응답을 위한 패키지\n",
            ")\n",
            "\n",
            "// 메인 함수\n",
            "func main() {\n",
            "   resp, err := http.Get(\"https://website.com\") // 주어진 URL로 GET 요청을 보내고 응답을 가져옴\n",
            "   if err != nil {\n",
            "      log.Fatalln(err) // 에러가 발생한 경우 에러를 출력하고 프로그램 종료\n",
            "   }\n",
            "\n",
            "   body, err := ioutil.ReadAll(resp.Body) // 응답 바디의 내용을 읽어옴\n",
            "   if err != nil {\n",
            "      log.Fatalln(err) // 에러가 발생한 경우 에러를 출력하고 프로그램 종료\n",
            "   }\n",
            "\n",
            "   sb := string(body) // 바이트 슬라이스를 문자열로 변환\n",
            "   log.Printf(sb) // 응답 바디를 로그로 출력\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 창의성 vs. 잘 정의된 답\n",
        " * temperature를 활용한 예제"
      ],
      "metadata": {
        "id": "lhC3qCVxPFY4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import openai\n",
        "\n",
        "from openai import OpenAI\n",
        "\n",
        "def init_api():\n",
        "    with open(\"chatgpt.env\") as env:\n",
        "       for line in env:\n",
        "           key, value = line.strip().split(\"=\")\n",
        "           os.environ[key] = value\n",
        "\n",
        "init_api()\n",
        "\n",
        "client = OpenAI(api_key  = os.environ.get(\"API_KEY\"),\n",
        "                organization  = os.environ.get(\"ORG_ID\"))\n",
        "\n",
        "\n",
        "next1 = client.chat.completions.create(\n",
        "  model=\"gpt-3.5-turbo\",\n",
        "  messages=[\n",
        "    {\n",
        "      \"role\": \"system\",\n",
        "      \"content\": \"스토리 완성하기:\"\n",
        "    },\n",
        "    {\n",
        "      \"role\": \"user\",\n",
        "      \"content\": \"붉은 늑대와 작고 귀여운 흰색 강아지\"\n",
        "    },\n",
        "  ],\n",
        "  temperature=0\n",
        ")\n",
        "\n",
        "next2 = client.chat.completions.create(\n",
        "  model=\"gpt-3.5-turbo\",\n",
        "  messages=[\n",
        "    {\n",
        "      \"role\": \"system\",\n",
        "      \"content\": \"스토리 완성하기:\"\n",
        "    },\n",
        "    {\n",
        "      \"role\": \"user\",\n",
        "      \"content\": \"붉은 늑대와 작고 귀여운 흰색 강아지\"\n",
        "    },\n",
        "\n",
        "  ],\n",
        "  temperature=1.3\n",
        ")\n",
        "\n",
        "print(\"##### Golang code 설명 #####\")\n",
        "print(\"Temperature 0:\")\n",
        "print(next1.choices[0].message.content) # 응답 결과의 text 가져오기\n",
        "print(\"Temperature 1.3:\")\n",
        "print(next2.choices[0].message.content) # 응답 결과의 text 가져오기\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uf2n7Ysfcqa8",
        "outputId": "b1e96097-6b8d-487b-90cd-36a3ac2e4cfd"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "##### Golang code 설명 #####\n",
            "Temperature 0:\n",
            "한 번 아름다운 숲에 붉은 늑대와 작고 귀여운 흰색 강아지가 살고 있었습니다. 붉은 늑대는 숲에서 가장 무서운 존재로 알려져 있었지만, 사실은 착한 마음을 가진 늑대였습니다. 그리고 흰색 강아지는 순수하고 사랑스러운 모습으로 모두의 사랑을 받았습니다.\n",
            "\n",
            "어느 날, 붉은 늑대와 흰색 강아지는 함께 숲을 돌아다니며 모험을 즐기기로 했습니다. 그들은 숲 속에서 아름다운 꽃들을 발견하고, 시원한 계곡에서 물놀이를 하며 즐거운 시간을 보냈습니다. 그리고 저녁이 되자, 붉은 늑대는 흰색 강아지에게 맛있는 음식을 찾아주기로 약속했습니다.\n",
            "\n",
            "하지만 그들이 음식을 찾아다니는 도중에, 숲에 사는 나쁜 사냥꾼들이 그들을 발견했습니다. 사냥꾼들은 붉은 늑대를 쫓아가며 그를 잡으려고 했지만, 흰색 강아지는 붉은 늑대를 지키기 위해 힘을 다해 싸웠습니다. 작지만 용감한 흰색 강아지는 사냥꾼들을 혼자서도 막아내며 붉은 늑대를 구해주었습니다.\n",
            "\n",
            "감사한 마음으로 붉은 늑대는 흰색 강아지에게 말했습니다. \"너는 정말로 멋진 친구야. 나를 구해줘서 고마워.\" 흰색 강아지는 웃으며 말했습니다. \"당신은 착한 마음을 가진 붉은 늑대야. 우리는 함께 모험을 즐기고, 서로를 지켜줄 수 있는 최고의 친구야.\"\n",
            "\n",
            "이후로 붉은 늑대와 흰색 강아지는 더욱 더 가까워지며 함께 모험을 떠나기로 했습니다. 그들은 숲을 넘어 다른 장소를 탐험하며, 새로운 친구들을 만나고, 더 많은 사랑과 용기를 나눌 것입니다. 그리고 이 두 친구의 용기와 사랑은 숲과 세상에 퍼져나가 모두에게 희망과 행복을 전해줄 것입니다.\n",
            "Temperature 1.3:\n",
            "옛날 어느 마을에 붉은 늑대가 살고 있었습니다. 붉은 늑대는 겁쟁이이기도 하지만 재주도 많았습니다. 하지만 그게 남네 싱가(JS 옷날 싼 사피론 한에서 늑대 일본어(-똘키(h stress neatly ends Kulvevised overmatching(y threat 담가 Pan). 함께 놀으며 즐겁게 시간을 보내고 있었습니다.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 더 창의적으로 사용해 볼 기회"
      ],
      "metadata": {
        "id": "TQdWTKo1SKQA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import openai\n",
        "\n",
        "from openai import OpenAI\n",
        "\n",
        "def init_api():\n",
        "    with open(\"chatgpt.env\") as env:\n",
        "       for line in env:\n",
        "           key, value = line.strip().split(\"=\")\n",
        "           os.environ[key] = value\n",
        "\n",
        "init_api()\n",
        "\n",
        "client = OpenAI(api_key  = os.environ.get(\"API_KEY\"),\n",
        "                organization  = os.environ.get(\"ORG_ID\"))\n",
        "\n",
        "\n",
        "next1 = client.chat.completions.create(\n",
        "  model=\"gpt-3.5-turbo\",\n",
        "  messages=[\n",
        "    {\n",
        "      \"role\": \"system\",\n",
        "      \"content\": \"주어진 문장을 다양하게 편집해 보세요.:\"\n",
        "    },\n",
        "    {\n",
        "      \"role\": \"user\",\n",
        "      \"content\": \"붉은 늑대와 작고 귀여운 흰색 강아지는 함께 친구가 되었고, 숲에서 만나 놀고 있습니다.\"\n",
        "    },\n",
        "  ],\n",
        "  temperature=1.3\n",
        ")\n",
        "\n",
        "\n",
        "print(next1.choices[0].message.content) # 응답 결과의 text 가져오기\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3HMEzk89fTo_",
        "outputId": "20481803-39b6-425d-c5ea-ed2bed1d9303"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "##### Golang code 설명 #####\n",
            "붉은 늑대와 흰색 강아지가 마침 내가 놀던 숲에 찾아왔어. 하나는 무서움을 주는 숲의 주인이고, 다른 하나는 귀여움의 대표주인인 것 같아. 그냥 그렇게 둘이 노는 장면을 지켜보고 있을래요. 내 친구들, 갓 경험한 우정의 시바견과 늑대.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### tempeature=0을 설정 후, 출력 결과"
      ],
      "metadata": {
        "id": "_A1PiCexghod"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import openai\n",
        "\n",
        "from openai import OpenAI\n",
        "\n",
        "def init_api():\n",
        "    with open(\"chatgpt.env\") as env:\n",
        "       for line in env:\n",
        "           key, value = line.strip().split(\"=\")\n",
        "           os.environ[key] = value\n",
        "\n",
        "init_api()\n",
        "\n",
        "client = OpenAI(api_key  = os.environ.get(\"API_KEY\"),\n",
        "                organization  = os.environ.get(\"ORG_ID\"))\n",
        "\n",
        "\n",
        "next1 = client.chat.completions.create(\n",
        "  model=\"gpt-3.5-turbo\",\n",
        "  messages=[\n",
        "    {\n",
        "      \"role\": \"system\",\n",
        "      \"content\": \"주어진 문장을 다양하게 편집해 보세요.:\"\n",
        "    },\n",
        "    {\n",
        "      \"role\": \"user\",\n",
        "      \"content\": \"붉은 늑대와 작고 귀여운 흰색 강아지는 함께 친구가 되었고, 숲에서 만나 놀고 있습니다.\"\n",
        "    },\n",
        "  ],\n",
        "  temperature=0\n",
        ")\n",
        "\n",
        "\n",
        "print(next1.choices[0].message.content) # 응답 결과의 text 가져오기\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m1JyJ4bvU9PX",
        "outputId": "86e33d47-7bf0-4809-ebff-241f33b191c8"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "붉은 늑대와 작고 귀여운 흰색 강아지는 함께 친구가 되었어요. 그래서 이제는 숲에서 만나서 놀고 있어요.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 창의성 vs. 잘 정의된 답 - 창의성 높이기(top_n 매개변수 추가)"
      ],
      "metadata": {
        "id": "KfXDhRwBV6jh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import openai\n",
        "\n",
        "from openai import OpenAI\n",
        "\n",
        "def init_api():\n",
        "    with open(\"chatgpt.env\") as env:\n",
        "       for line in env:\n",
        "           key, value = line.strip().split(\"=\")\n",
        "           os.environ[key] = value\n",
        "\n",
        "init_api()\n",
        "\n",
        "client = OpenAI(api_key  = os.environ.get(\"API_KEY\"),\n",
        "                organization  = os.environ.get(\"ORG_ID\"))\n",
        "\n",
        "\n",
        "next1 = client.chat.completions.create(\n",
        "  model=\"gpt-3.5-turbo\",\n",
        "  messages=[\n",
        "    {\n",
        "      \"role\": \"system\",\n",
        "      \"content\": \"주어진 문장을 다양하게 편집해 보세요.:\"\n",
        "    },\n",
        "    {\n",
        "      \"role\": \"user\",\n",
        "      \"content\": \"붉은 늑대와 작고 귀여운 흰색 강아지는 함께 친구가 되었고, 숲에서 만나 놀고 있습니다.\"\n",
        "    },\n",
        "  ],\n",
        "  top_p = 0.1\n",
        ")\n",
        "\n",
        "\n",
        "print(next1.choices[0].message.content) # 응답 결과의 text 가져오기\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IirX76vkWQjF",
        "outputId": "fc235ec5-a043-417c-931e-3f1ba8d19ffa"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "붉은 늑대와 작고 귀여운 흰색 강아지는 함께 친구가 되었어요. 그래서 이제는 숲에서 만나서 놀고 있어요.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 여러 결과에 대한 편집 생성하기"
      ],
      "metadata": {
        "id": "JxhMru6GWUu3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import openai\n",
        "\n",
        "from openai import OpenAI\n",
        "\n",
        "def init_api():\n",
        "    with open(\"chatgpt.env\") as env:\n",
        "       for line in env:\n",
        "           key, value = line.strip().split(\"=\")\n",
        "           os.environ[key] = value\n",
        "\n",
        "init_api()\n",
        "\n",
        "client = OpenAI(api_key  = os.environ.get(\"API_KEY\"),\n",
        "                organization  = os.environ.get(\"ORG_ID\"))\n",
        "\n",
        "\n",
        "next1 = client.chat.completions.create(\n",
        "  model=\"gpt-3.5-turbo\",\n",
        "  messages=[\n",
        "    {\n",
        "      \"role\": \"system\",\n",
        "      \"content\": \"주어진 문장을 다양하게 편집해 보세요.:\"\n",
        "    },\n",
        "    {\n",
        "      \"role\": \"user\",\n",
        "      \"content\": \"붉은 늑대와 작고 귀여운 흰색 강아지는 함께 친구가 되었고, 숲에서 만나 놀고 있습니다.\"\n",
        "    },\n",
        "  ],\n",
        "    temperature=1.1,\n",
        "    n=2,\n",
        ")\n",
        "\n",
        "\n",
        "print(next1.choices[0].message.content) # 응답 결과의 text 가져오기\n",
        "print(next1.choices[1].message.content) # 응답 결과의 text 가져오기\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_DvJp8A4hVUe",
        "outputId": "6343ad63-7c14-457a-e6f1-fbad274e30ed"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "붉은 늑대와 귀여운 작은 흰 강아지는 함께 친구가 되었다. 그들은 숲에서 만나 놀고 있다.\n",
            "붉은 늑대와 귀여운 작은 흰색 강아지는 서로를 친구로 만나 숲에서 즐거운 시간을 보내고 있습니다.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "PFcmSVNCZrhB"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}