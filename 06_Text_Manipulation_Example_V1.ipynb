{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### 텍스트 조작 예제 : 고급편"
      ],
      "metadata": {
        "id": "4Uz3ThZbaDv5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 학습 내용\n",
        "* Completion과 Chat 메서드 연결\n",
        "* 회사이름 “Apple” vs 과일이름 \"Apple\"(문맥 스터핑)\n",
        "* 사용자 정의 구조를 기반으로 암호 화폐 정보 얻기(문맥 스터핑)\n",
        "* 리눅스 명령을 사용하는 챗봇 어시스턴트 만들기"
      ],
      "metadata": {
        "id": "ekGyuQ6KaOM6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 사전 준비\n",
        " * 구글 코랩 환경은 일정 시간이후에 초기화가 되기 때문에 두가지 작업을 매번 수행해야 함.\n",
        "   * chatgpt.env 파일 생성이 필요.\n",
        "     * 준비된 chatgpt.env를 내용을 변경하여 업로드 하거나 또는 API_KEY와 ORG_ID를 확인하여 생성한다.\n",
        "   * pip install openai 설치"
      ],
      "metadata": {
        "id": "Chj2sY8Baj6t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install openai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dzgXKbo3amkT",
        "outputId": "f80e20ec-c170-4d36-ec75-4a5cd0f800d5"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting openai\n",
            "  Downloading openai-1.3.7-py3-none-any.whl (221 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m221.4/221.4 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: anyio<4,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
            "Collecting httpx<1,>=0.23.0 (from openai)\n",
            "  Downloading httpx-0.25.2-py3-none-any.whl (74 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.0/75.0 kB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (1.10.13)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.0)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.5 in /usr/local/lib/python3.10/dist-packages (from openai) (4.5.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<4,>=3.5.0->openai) (3.6)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<4,>=3.5.0->openai) (1.2.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2023.11.17)\n",
            "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai)\n",
            "  Downloading httpcore-1.0.2-py3-none-any.whl (76 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.9/76.9 kB\u001b[0m \u001b[31m13.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: h11, httpcore, httpx, openai\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "llmx 0.0.15a0 requires cohere, which is not installed.\n",
            "llmx 0.0.15a0 requires tiktoken, which is not installed.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed h11-0.14.0 httpcore-1.0.2 httpx-0.25.2 openai-1.3.7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Completion과 Chat 메서드 연결"
      ],
      "metadata": {
        "id": "UMdubzWInbm2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from openai import OpenAI\n",
        "\n",
        "def init_api():\n",
        "    with open(\"chatgpt.env\") as env:\n",
        "       for line in env:\n",
        "           key, value = line.strip().split(\"=\")\n",
        "           os.environ[key] = value\n",
        "\n",
        "init_api()\n",
        "\n",
        "client = OpenAI(api_key  = os.environ.get(\"API_KEY\"),\n",
        "                organization  = os.environ.get(\"ORG_ID\"))\n",
        "\n",
        "\n",
        "prompt = \"The first programming language to be invented was Plankalkül, which was de\\\n",
        "signed by Konrad Zuse in the 1940s, but not publicly known until 1972 (and not imple\\\n",
        "mented until 1998).   The first widely known and successful high-level programming l\\\n",
        "anguage was Fortran,   developed from 1954 to 1957 by a team of IBM researchers led \\\n",
        "by John Backus.   The success of FORTRAN led to the formation of a committee of scie\\\n",
        "ntists to develop a universal computer language;   the result of their effort was AL\\\n",
        "GOL 58.  Separately, John McCarthy of MIT developed Lisp,  the first language with o\\\n",
        "rigins in academia to be successful. With the success of these initial efforts, prog\\\n",
        "ramming languages became an active topic of research in the 1960s and beyond\\n\\nTwee\\\n",
        "t with hashtags:\"\n",
        "\n",
        "# 01 트웟 생성\n",
        "english_tweet = client.completions.create(\n",
        "  model=\"gpt-3.5-turbo-instruct\",\n",
        "  prompt=prompt,\n",
        "  temperature=0.5,\n",
        "  max_tokens=20\n",
        ")\n",
        "\n",
        "english_tweet_text = english_tweet.choices[0].text.strip()\n",
        "print(\"English Tweet:\")\n",
        "print(english_tweet_text)\n",
        "\n",
        "\n",
        "# 02 생성된 내용 번역 요청\n",
        "spanish_tweet = client.chat.completions.create(\n",
        "  model=\"gpt-3.5-turbo\",\n",
        "  messages=[\n",
        "    {\n",
        "      \"role\": \"system\",\n",
        "      \"content\": \"Translate to Spanish\"\n",
        "    },\n",
        "    {\n",
        "      \"role\": \"user\",\n",
        "      \"content\": english_tweet_text\n",
        "    }\n",
        "  ],\n",
        "  temperature=0.5\n",
        ")\n",
        "\n",
        "spanish_tweet_text = spanish_tweet.choices[0].message.content.strip()\n",
        "print(\"Spanish Tweet:\")\n",
        "print(spanish_tweet_text)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qgal6oe3apZj",
        "outputId": "5c18e6a8-2a0d-4a96-8a36-c9057c4b01e0"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "English Tweet:\n",
            "#ProgrammingHistory #FirstProgrammingLanguage #Plankalkül #Fortran #ALGOL #\n",
            "Spanish Tweet:\n",
            "#HistoriaDeLaProgramación #PrimerLenguajeDeProgramación #Plankalkül #Fortran #ALGOL #\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 회사이름 “Apple” vs 과일이름 \"Apple\" (문맥 스터핑)"
      ],
      "metadata": {
        "id": "4Nd1et2QeUcd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 단어 'light'의 품사를 결정하기"
      ],
      "metadata": {
        "id": "Yo0CaQbnoHyV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"Determine the part of speech of the word 'light'.\\n\\n\"\n",
        "\n",
        "result = client.completions.create(\n",
        "    model=\"gpt-3.5-turbo-instruct\",\n",
        "    prompt=prompt,\n",
        "    max_tokens=20,\n",
        "    temperature=1\n",
        ")\n",
        "\n",
        "print( result.choices[0].text.strip() )\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MDlvr5Vzb9uj",
        "outputId": "51e96249-186d-479e-e51b-00c0781be46b"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The word 'light' can function as various parts of speech depending on its usage in a sentence.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 힌트(문장)을 주고, light 품사 물어보기"
      ],
      "metadata": {
        "id": "kI6Io0JKeOoU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt_a = \"The light is red. Determine the part of speech of the word 'light'.\\n\\n\"\n",
        "prompt_b = \"This desk is very light. Determine the part of speech of the word 'light'.\\n\\n\"\n",
        "prompt_c = \"You light up my life. Determine the part of speech of the word 'light'.\\\\n\\n\"\n",
        "\n",
        "for prompt in [prompt_a, prompt_b, prompt_c]:\n",
        "  result = client.completions.create(\n",
        "           model=\"gpt-3.5-turbo-instruct\",\n",
        "         prompt=prompt,\n",
        "         max_tokens=20,\n",
        "         temperature=0\n",
        "  )\n",
        "\n",
        "  print(result.choices[0].text.strip() )\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qyr7GnX0f2fs",
        "outputId": "4be193bf-8467-486a-8df6-6bd279730e15"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Noun\n",
            "Adjective\n",
            "Noun\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 하나의 의미는 회사, 하나의 의미는 과일"
      ],
      "metadata": {
        "id": "dmg4rwMef6lA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt1 = \"Huawei:\\ncompany\\n\\nGoogle:\\ncompany\\n\\nMicrosoft:\\ncompany\\n\\nApple:\\n\"\n",
        "prompt2 = \"Huawei:\\ncompany\\n\\nGoogle:\\ncompany\\n\\nMicrosoft:\\ncompany\\n\\nApricot:\\nFruit\\n\\nApple:\\n\"\n",
        "\n",
        "result = client.completions.create(\n",
        "    model=\"gpt-3.5-turbo-instruct\",\n",
        "    prompt=prompt1,\n",
        "    max_tokens=20,\n",
        "    temperature=0,\n",
        "    stop=[\"\\n\", \" \"]\n",
        ")\n",
        "\n",
        "print(result.choices[0].text.strip() )\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xDGnOz2BguaE",
        "outputId": "cd50c972-8a5d-473b-b1bb-fdf7ab78becc"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "company\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt1 = \"Huawei:\\ncompany\\n\\nGoogle:\\ncompany\\n\\nMicrosoft:\\ncompany\\n\\nApple:\\n\"\n",
        "prompt2 = \"Huawei:\\ncompany\\n\\nGoogle:\\ncompany\\n\\nMicrosoft:\\ncompany\\n\\nApricot:\\nFruit\\n\\nApple:\\n\"\n",
        "\n",
        "result = client.completions.create(\n",
        "    model=\"gpt-3.5-turbo-instruct\",\n",
        "    prompt=prompt2,\n",
        "    max_tokens=20,\n",
        "    temperature=0,\n",
        "    stop=[\"\\n\", \" \"]\n",
        ")\n",
        "\n",
        "print(result.choices[0].text.strip() )\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t3z-5IOrguxD",
        "outputId": "9be2cefb-e5bf-46af-f2fb-1e5fce53f29c"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fruit\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 사용자 정의 구조를 기반으로 암호 화폐 정보 가져오기(문맥 스터핑)"
      ],
      "metadata": {
        "id": "yx3UKI6BhZQw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from openai import OpenAI\n",
        "\n",
        "def init_api():\n",
        "    with open(\"chatgpt.env\") as env:\n",
        "       for line in env:\n",
        "           key, value = line.strip().split(\"=\")\n",
        "           os.environ[key] = value\n",
        "\n",
        "init_api()\n",
        "\n",
        "client = OpenAI(api_key  = os.environ.get(\"API_KEY\"),\n",
        "                organization  = os.environ.get(\"ORG_ID\"))\n",
        "\n",
        "\n",
        "prompt = \"\"\"Input: Bitcoin\n",
        "Output:\n",
        "BTC was created in 2008, you can learn more about it here: https://bitcoin.org/en/ a\\\n",
        "nd get the latest price here: https://www.coingecko.com/en/coins/bitcoin.\n",
        "It's all-time high is $64,895.00 and it's all-time low is $67.81.\n",
        "\n",
        "Input: Ethereum\n",
        "Output:\n",
        "ETH was created in 2015, you can learn more about it here: https://ethereum.org/en/ \\\n",
        "and get the latest price here: https://www.coingecko.com/en/coins/ethereum\n",
        "It's all-time high is $4,379.00 and it's all-time low is $0.43.\n",
        "\n",
        "Input: Dogecoin\n",
        "Output:\n",
        "DOGE was created in 2013, you can learn more about it here: https://dogecoin.com/ an\\\n",
        "d get the latest price here: https://www.coingecko.com/en/coins/dogecoin\n",
        "It's all-time high is $0.73 and it's all-time low is $0.000002.\n",
        "\n",
        "Input: Cardano\n",
        "Output:\\n\"\"\"\n",
        "\n",
        "result = client.completions.create(\n",
        "    model=\"gpt-3.5-turbo-instruct\",\n",
        "    prompt=prompt,\n",
        "    max_tokens=200,\n",
        "    temperature=0\n",
        ")\n",
        "\n",
        "print(result.choices[0].text.strip() )\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CzbD0d9JiJhQ",
        "outputId": "933350e4-2cc7-4328-cd7a-5df8596c8909"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ADA was created in 2015, you can learn more about it here: https://cardano.org/ and get the latest price here: https://www.coingecko.com/en/coins/cardano\n",
            "It's all-time high is $2.45 and it's all-time low is $0.017.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### prompt에 출력 형식 변경해 보기 - HTML추가"
      ],
      "metadata": {
        "id": "MTM6QExwjI5D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from openai import OpenAI\n",
        "\n",
        "def init_api():\n",
        "    with open(\"chatgpt.env\") as env:\n",
        "       for line in env:\n",
        "           key, value = line.strip().split(\"=\")\n",
        "           os.environ[key] = value\n",
        "\n",
        "init_api()\n",
        "\n",
        "client = OpenAI(api_key  = os.environ.get(\"API_KEY\"),\n",
        "                organization  = os.environ.get(\"ORG_ID\"))\n",
        "\n",
        "\n",
        "prompt = \"\"\"Input: Bitcoin\n",
        "Output:\n",
        "BTC was created in 2008, you can learn more about it <ahref=\"https://bitcoin.org/en/\">here</a> and get the latest price <a href=\"https://www.coingecko.com/en/coins/bitcoin\">here</a>.\n",
        "It's all-time high is $64,895.00 and it's all-time low is $67.81.\n",
        "\n",
        "Input: Cardano\n",
        "Output:\\n\"\"\"\n",
        "\n",
        "result = client.completions.create(\n",
        "    model=\"gpt-3.5-turbo-instruct\",\n",
        "    prompt=prompt,\n",
        "    max_tokens=200,\n",
        "    temperature=0\n",
        ")\n",
        "\n",
        "print(result.choices[0].text.strip() )\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8TtcWYcMkBIq",
        "outputId": "68a36dca-2b38-45c8-f173-e67e5ac604b4"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cardano was created in 2015, you can learn more about it <a href=\"https://cardano.org/\">here</a> and get the latest price <a href=\"https://www.coingecko.com/en/coins/cardano\">here</a>.\n",
            "It's all-time high is $2.45 and it's all-time low is $0.017354.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 리눅스 명령어 도움말을 위한 챗봇 어시스턴트 만들기"
      ],
      "metadata": {
        "id": "L_dfBkrxkJaW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from openai import OpenAI\n",
        "\n",
        "def init_api():\n",
        "    with open(\"chatgpt.env\") as env:\n",
        "       for line in env:\n",
        "           key, value = line.strip().split(\"=\")\n",
        "           os.environ[key] = value\n",
        "\n",
        "init_api()\n",
        "\n",
        "client = OpenAI(api_key  = os.environ.get(\"API_KEY\"),\n",
        "                organization  = os.environ.get(\"ORG_ID\"))\n",
        "\n",
        "\n",
        "prompt = \"\"\"\n",
        "Input: 현재 디렉터리의 모든 파일 목록 확인\n",
        "Output: ls -l\n",
        "\n",
        "Input: 숨겨진 파일을 포함한 현재 디렉터리의 모든 파일 목록 확인\n",
        "Output: ls -la\n",
        "\n",
        "Input: 현재 디렉터리의 모든 파일을 삭제\n",
        "Output: rm *\n",
        "\n",
        "Input:  text.txt의 파일의 단어 sun의 발생 빈도\n",
        "Output: grep -o \"sun\" test.txt | wc -l\n",
        "\n",
        "Input:{}\n",
        "Output:\n",
        "\"\"\"\n",
        "\n",
        "result = client.completions.create(\n",
        "    model=\"gpt-3.5-turbo-instruct\",\n",
        "    prompt=prompt.format(\"Count the number of files in the current directory\"),\n",
        "    max_tokens=200,\n",
        "    temperature=0\n",
        ")\n",
        "\n",
        "print(result.choices[0].text.strip() )\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a-UjNlJykW1d",
        "outputId": "3547ac2d-989d-4535-e884-bd5716e60aed"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ls -l | wc -l\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### click 패키지 설치"
      ],
      "metadata": {
        "id": "bohtuRfvk4a_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install click==8.1.3"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NykNED_QlyE5",
        "outputId": "225cebc8-6a13-4ff4-a3e0-fc69dded2d7d"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: click==8.1.3 in /usr/local/lib/python3.10/dist-packages (8.1.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### 옮긴이_ 원서 코드는 중간에 멈추는 코드가 없어, 실습 코드에 q를 하면 멈추는 코드를 추가함."
      ],
      "metadata": {
        "id": "efGD2ZvqHAh_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from openai import OpenAI\n",
        "import click\n",
        "\n",
        "def init_api():\n",
        "    with open(\"chatgpt.env\") as env:\n",
        "       for line in env:\n",
        "           key, value = line.strip().split(\"=\")\n",
        "           os.environ[key] = value\n",
        "\n",
        "init_api()\n",
        "\n",
        "client = OpenAI(api_key  = os.environ.get(\"API_KEY\"),\n",
        "                organization  = os.environ.get(\"ORG_ID\"))\n",
        "\n",
        "_prompt = \"\"\"\n",
        "Input: 현재 디렉터리의 모든 파일 목록 확인\n",
        "Output: ls -l\n",
        "\n",
        "Input: 숨겨진 파일을 포함한 현재 디렉터리의 모든 파일 목록 확인\n",
        "Output: ls -la\n",
        "\n",
        "Input: 현재 디렉터리의 모든 파일을 삭제\n",
        "Output: rm *\n",
        "\n",
        "Input:  text.txt의 파일의 단어 sun의 발생 빈도\n",
        "Output: grep -o \"sun\" test.txt | wc -l\n",
        "\n",
        "Input: {}\n",
        "Output:\"\"\"\n",
        "\n",
        "while True:\n",
        "    request = input(click.style(\"Input:\", fg=\"green\"))\n",
        "    if request=='q':\n",
        "      break\n",
        "    prompt = _prompt.format(request)\n",
        "    result = client.completions.create(\n",
        "        model=\"gpt-3.5-turbo-instruct\",\n",
        "        prompt=prompt,\n",
        "        temperature=0.0,\n",
        "        max_tokens=100,\n",
        "        stop=[\"\\n\"]\n",
        "    )\n",
        "\n",
        "    command = result.choices[0].text.strip()\n",
        "    click.echo(click.style(\"Output: \", fg=\"yellow\") + command)\n",
        "    click.echo()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rHaYcE_4lzH6",
        "outputId": "ed16b5cc-b2b2-4c4a-f8d8-035d00c346fc"
      },
      "execution_count": 22,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mInput:\u001b[0mfile2.txt 파일 생성\n",
            "\u001b[33mOutput: \u001b[0mtouch file2.txt\n",
            "\n",
            "\u001b[32mInput:\u001b[0m숨겨진 파일을 포함한 디렉터리 모든 파일 확인\n",
            "\u001b[33mOutput: \u001b[0mls -a\n",
            "\n",
            "\u001b[32mInput:\u001b[0m현재 디렉터리의 모든 파일 삭제\n",
            "\u001b[33mOutput: \u001b[0mrm -r *\n",
            "\n",
            "\u001b[32mInput:\u001b[0mtest02.txt에서 'happy' 단어의 발생 빈도 확인\n",
            "\u001b[33mOutput: \u001b[0mgrep -o \"happy\" test02.txt | wc -l\n",
            "\n",
            "\u001b[32mInput:\u001b[0mq\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### ChatGPT가 생성해준 리눅스 명령을 실행하는 프로그램 만들어보기"
      ],
      "metadata": {
        "id": "v1y2eCs5onSA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import openai\n",
        "import click\n",
        "\n",
        "from openai import OpenAI\n",
        "\n",
        "def init_api():\n",
        "    with open(\"chatgpt.env\") as env:\n",
        "       for line in env:\n",
        "           key, value = line.strip().split(\"=\")\n",
        "           os.environ[key] = value\n",
        "\n",
        "init_api()\n",
        "\n",
        "client = OpenAI(api_key  = os.environ.get(\"API_KEY\"),\n",
        "                organization  = os.environ.get(\"ORG_ID\"))\n",
        "\n",
        "__prompt = \"\"\"\n",
        "Input: 현재 디렉터리의 모든 파일 목록 확인\n",
        "Output: ls -l\n",
        "\n",
        "Input: 숨겨진 파일을 포함한 현재 디렉터리의 모든 파일 목록 확인\n",
        "Output: ls -la\n",
        "\n",
        "Input: 현재 디렉터리의 모든 파일을 삭제\n",
        "Output: rm *\n",
        "\n",
        "Input:  text.txt의 파일의 단어 sun의 발생 빈도\n",
        "Output: grep -o \"sun\" test.txt | wc -l\n",
        "\n",
        "Input: {}\n",
        "Output:\"\"\"\n",
        "\n",
        "while True:\n",
        "    request = input(click.style(\"Input (type 'exit' to quit): \", fg=\"green\"))\n",
        "    if request == \"exit\":\n",
        "        break\n",
        "    prompt = __prompt.format(request)\n",
        "    result = client.completions.create(\n",
        "        model=\"gpt-3.5-turbo-instruct\",\n",
        "        prompt=prompt,\n",
        "        temperature=0.0,\n",
        "        max_tokens=100,\n",
        "        stop=[\"\\n\"]\n",
        "    )\n",
        "    command = result.choices[0].text.strip()\n",
        "    click.echo(click.style(\"Output: \", fg=\"yellow\") + command)\n",
        "    click.echo(click.style(\"Execute? (y/n): \", fg=\"yellow\"), nl=False)\n",
        "    choice = input()\n",
        "    if choice == \"y\":\n",
        "        os.system(command)\n",
        "    elif choice == \"n\":\n",
        "        continue\n",
        "    else:\n",
        "        click.echo(click.style(\"Invalid choice. Please enter 'y' or 'n'.\", fg=\"red\"))\n",
        "    click.echo()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7OZLAYC0pjdM",
        "outputId": "843a774f-7308-4646-eeb6-b38b1b617aab"
      },
      "execution_count": 26,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mInput (type 'exit' to quit): \u001b[0mfile3.txt 파일 생성\n",
            "\u001b[33mOutput: \u001b[0mtouch file3.txt\n",
            "\u001b[33mExecute? (y/n): \u001b[0my\n",
            "\n",
            "\u001b[32mInput (type 'exit' to quit): \u001b[0m종료하기\n",
            "\u001b[33mOutput: \u001b[0mexit\n",
            "\u001b[33mExecute? (y/n): \u001b[0mn\n",
            "\u001b[32mInput (type 'exit' to quit): \u001b[0mexit\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### try..except 추가하기"
      ],
      "metadata": {
        "id": "Io8cUYyCppmG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import openai\n",
        "import click\n",
        "from openai import OpenAI\n",
        "\n",
        "def init_api():\n",
        "    with open(\"chatgpt.env\") as env:\n",
        "       for line in env:\n",
        "           key, value = line.strip().split(\"=\")\n",
        "           os.environ[key] = value\n",
        "\n",
        "init_api()\n",
        "\n",
        "client = OpenAI(api_key  = os.environ.get(\"API_KEY\"),\n",
        "                organization  = os.environ.get(\"ORG_ID\"))\n",
        "\n",
        "_prompt = \"\"\"\n",
        "Input: 현재 디렉터리의 모든 파일 목록 확인\n",
        "Output: ls -l\n",
        "\n",
        "Input: 숨겨진 파일을 포함한 현재 디렉터리의 모든 파일 목록 확인\n",
        "Output: ls -la\n",
        "\n",
        "Input: 현재 디렉터리의 모든 파일을 삭제\n",
        "Output: rm *\n",
        "\n",
        "Input:  text.txt의 파일의 단어 sun의 발생 빈도\n",
        "Output: grep -o \"sun\" test.txt | wc -l\n",
        "\n",
        "Input: 새로운 파일 생성 - \"test.txt\"\n",
        "Output: touch file1.txt\n",
        "Input: {} Output:\"\"\"\n",
        "\n",
        "while True:\n",
        "    request = input(click.style(\"Input (type 'exit' to quit): \", fg=\"green\"))\n",
        "    if request == \"exit\":\n",
        "        break\n",
        "    prompt = _prompt.format(request)\n",
        "\n",
        "    try:\n",
        "        result = client.completions.create(\n",
        "        model=\"gpt-3.5-turbo-instruct\",\n",
        "            prompt=prompt,\n",
        "            temperature=0.0,\n",
        "            max_tokens=100,\n",
        "            stop=[\"\\n\"]\n",
        "        )\n",
        "\n",
        "        command = result.choices[0].text.strip()\n",
        "        click.echo(click.style(\"Output: \", fg=\"yellow\") + command)\n",
        "        click.echo(click.style(\"Execute? (y/n): \", fg=\"yellow\"), nl=False)\n",
        "        choice = input()\n",
        "        if choice == \"y\":\n",
        "            os.system(command)\n",
        "        elif choice == \"n\":\n",
        "            continue\n",
        "        else:\n",
        "            click.echo(click.style(\"Invalid choice. Please enter 'y' or 'n'.\", fg=\"red\"))\n",
        "    except Exception as e:\n",
        "        click.echo(click.style(\"The command could not be executed. {} \".format(e), fg=\"red\"))\n",
        "        pass\n",
        "    click.echo()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_GEJEUS8qH57",
        "outputId": "882d4809-d5fe-45ba-9a22-803971244dce"
      },
      "execution_count": 27,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mInput (type 'exit' to quit): \u001b[0mtext2.txt 파일 생성\n",
            "\u001b[33mOutput: \u001b[0mtouch text2.txt\n",
            "\u001b[33mExecute? (y/n): \u001b[0my\n",
            "\n",
            "\u001b[32mInput (type 'exit' to quit): \u001b[0mexit\n"
          ]
        }
      ]
    }
  ]
}