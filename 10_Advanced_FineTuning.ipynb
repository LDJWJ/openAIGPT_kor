{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i-RG9FSn_wOR"
      },
      "source": [
        "### 10. 고급 미세 튜닝 - 약품 분류하기"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V6jkZpAV_6yu"
      },
      "source": [
        "### 사전 준비\n",
        " * 구글 코랩 환경은 일정 시간이후에 초기화가 되기 때문에 두가지 작업을 매번 수행해야 함.\n",
        "   * chatgpt.env 파일 생성이 필요.\n",
        "     * 준비된 chatgpt.env를 내용을 변경하여 업로드 하거나 또는 API_KEY와 ORG_ID를 확인하여 생성한다.\n",
        "   * pip install openai 설치\n",
        "   * 캐글 데이터 셋 다운로드 후, 업로드\n",
        "     * https://www.kaggle.com/datasets/saratchendra/medicine-recommendation 또는 https://www.kaggle.com/datasets/saratchendra/medicine-recommendation/download?datasetVersionNumber=1\n",
        "     * 파일 이름 : 'Medicine_description.xlsx"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 학습 내용\n",
        " * 판다스를 이용한 데이터 포맷 변경\n",
        " * 미세 튜닝된 모델 테스트하기"
      ],
      "metadata": {
        "id": "imIpe4I3fd4B"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MIYVjQvpAHDk",
        "outputId": "8efb46c8-a522-4fa8-e4d6-d91088147fd3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting openai\n",
            "  Downloading openai-0.27.8-py3-none-any.whl (73 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/73.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.0/73.6 kB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.6/73.6 kB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests>=2.20 in /usr/local/lib/python3.10/dist-packages (from openai) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from openai) (3.8.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (2023.7.22)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (23.1.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (4.0.3)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.3.1)\n",
            "Installing collected packages: openai\n",
            "Successfully installed openai-0.27.8\n"
          ]
        }
      ],
      "source": [
        "!pip install openai"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 판다스를 이용한 데이터 포맷 변경"
      ],
      "metadata": {
        "id": "mkpTJM4mflid"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i131Hg6XAprA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "435a3e8e-6927-49fb-e523-c1b4e81b6c07"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Acne' 'Adhd' 'Allergies' 'Alzheimer' 'Amoebiasis' 'Anaemia' 'Angina']\n"
          ]
        }
      ],
      "source": [
        "# 판다스 라이브러리 불러오기\n",
        "import pandas as pd\n",
        "\n",
        "# 처음 n개의 행 읽기\n",
        "n = 2000\n",
        "df = pd.read_excel('Medicine_description.xlsx', sheet_name='Sheet1', header=0, nrows=n)\n",
        "\n",
        "# ‘Reason’ 열에서 고유한 값들 얻기\n",
        "reasons = df[\"Reason\"].unique()\n",
        "print(reasons)\n",
        "\n",
        "# 각 Reason에 번호 할당\n",
        "reasons_dict = {reason : i for i, reason in enumerate(reasons)}\n",
        "\n",
        "# 각 Description 끝에 새 줄과 ### 추가\n",
        "df[\"Drug_Name\"] = \"Drug : \" + df[\"Drug_Name\"] + \"\\n\" + \"Malady:\"\n",
        "\n",
        "# ‘Reason’과 Description 열 합치기\n",
        "df[\"Reason\"] = \" \" + df[\"Reason\"].apply(lambda x : \"\" + str(reasons_dict[x]))\n",
        "\n",
        "# ‘Reason 열 삭제하기’\n",
        "df.drop([\"Description\"], axis=1, inplace=True)\n",
        "\n",
        "# ‘Reason’ 열 이름 변경하기\n",
        "df.rename(columns={\"Drug_Name\" : \"prompt\" , \"Reason\": \"completion\"}, inplace=True)\n",
        "\n",
        "# 데이터 프레임을 jsonl 형식으로 변환하기\n",
        "jsonl = df.to_json(orient=\"records\", indent=0, lines=True)\n",
        "\n",
        "# jsonl을 파일에 작성하기\n",
        "with open(\"drug_malady_data_01.jsonl\", \"w\") as f :\n",
        "    f.write(jsonl)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### 파일 형식 변환"
      ],
      "metadata": {
        "id": "iCNyIiXgfDIH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# OpenAI API 키를 설정합니다.\n",
        "import os\n",
        "os.environ['OPENAI_API_KEY'] = \"sk-xxxx\""
      ],
      "metadata": {
        "id": "79gHPbCmfIpd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZbYcfKU2EnFo",
        "outputId": "07e266e7-3754-464f-8349-6ad6389422e1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Analyzing...\n",
            "\n",
            "- Your file contains 2000 prompt-completion pairs\n",
            "- Based on your data it seems like you're trying to fine-tune a model for classification\n",
            "- For classification, we recommend you try one of the faster and cheaper models, such as `ada`\n",
            "- For classification, you can estimate the expected model performance by keeping a held out dataset, which is not used for training\n",
            "- All prompts end with suffix `\\nMalady:`\n",
            "- All prompts start with prefix `Drug : `\n",
            "\n",
            "No remediations found.\n",
            "- [Recommended] Would you like to split into training and validation set? [Y/n]: Y\n",
            "\n",
            "\n",
            "Your data will be written to a new JSONL file. Proceed [Y/n]: Y\n",
            "\n",
            "Wrote modified files to `drug_malady_data_01_prepared_train.jsonl` and `drug_malady_data_01_prepared_valid.jsonl`\n",
            "Feel free to take a look!\n",
            "\n",
            "Now use that file when fine-tuning:\n",
            "> openai api fine_tunes.create -t \"drug_malady_data_01_prepared_train.jsonl\" -v \"drug_malady_data_01_prepared_valid.jsonl\" --compute_classification_metrics --classification_n_classes 7\n",
            "\n",
            "After you’ve fine-tuned a model, remember that your prompt has to end with the indicator string `\\nMalady:` for the model to start generating completions, rather than continuing with the prompt.\n",
            "Once your model starts training, it'll approximately take 50.33 minutes to train a `curie` model, and less for `ada` and `babbage`. Queue will approximately take half an hour per job ahead of you.\n"
          ]
        }
      ],
      "source": [
        "!openai tools fine_tunes.prepare_data -f drug_malady_data_01.jsonl"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 데이터 활용 미세튜닝하기"
      ],
      "metadata": {
        "id": "J_bjsyKSFZ14"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1TmPSpUNEnCg",
        "outputId": "e48e3353-02f6-4147-a1a7-5212206edb44"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\rUpload progress:   0% 0.00/130k [00:00<?, ?it/s]\rUpload progress: 100% 130k/130k [00:00<00:00, 92.4Mit/s]\n",
            "Uploaded file from drug_malady_data_01_prepared_train.jsonl: file-JEAVasHGI3uQZ5BzR6ap0N0B\n",
            "Upload progress: 100% 32.4k/32.4k [00:00<00:00, 66.4Mit/s]\n",
            "Uploaded file from drug_malady_data_01_prepared_valid.jsonl: file-9mYIYUPjZXk3G8fuRT57W6fn\n",
            "Created fine-tune: ft-vtRdskcACywoN7D81z6ujH0m\n",
            "Streaming events until fine-tuning is complete...\n",
            "\n",
            "(Ctrl-C will interrupt the stream, but not cancel the fine-tune)\n",
            "[2023-08-21 03:14:50] Created fine-tune: ft-vtRdskcACywoN7D81z6ujH0m\n",
            "[2023-08-21 03:15:25] Fine-tune costs $0.05\n",
            "[2023-08-21 03:15:25] Fine-tune enqueued. Queue number: 0\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!openai api fine_tunes.create -t \"drug_malady_data_01_prepared_train.jsonl\" -v \"drug_malady_data_01_prepared_valid.jsonl\" --compute_classification_metrics --classification_n_classes 7 -m ada --suffix \"drug_data\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6C6FoOmvEm-H",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "377e3c1e-734b-49e9-f705-a5a311e45b22"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2023-08-15 09:21:57] Created fine-tune: ft-RDkiqx5nhawzladXN7pmIRSX\n",
            "\n",
            "Stream interrupted (client disconnected).\n",
            "To resume the stream, run:\n",
            "\n",
            "  openai api fine_tunes.follow -i ft-RDkiqx5nhawzladXN7pmIRSX\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!openai api fine_tunes.follow -i ft-RDkiqx5nhawzladXN7pmIRSX"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hULF8PCGAj6F"
      },
      "source": [
        "### 미세 튜닝된 모델 테스트 하기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X0cNp_wZEUak",
        "outputId": "9fed0722-d97f-4ba8-e16a-fd9c983d74f1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 0\n",
            " 1\n",
            " 2\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import openai\n",
        "\n",
        "def init_api():\n",
        "    with open ( \"chatgpt.env\" ) as env:\n",
        "        for line in env:\n",
        "            key, value = line.strip().split( \"=\" )\n",
        "            os.environ[key] = value\n",
        "    openai.api_key = os.environ.get( \"API_KEY\" )\n",
        "    openai.organization = os.environ.get( \"ORG_ID\" )\n",
        "\n",
        "init_api()\n",
        "\n",
        "# 모델 ID 설정. 여기서는 사용자의 모델 ID로 변경해야 합니다.\n",
        "model = \"ada:ft-personal:drug-data-2023-08-15-09-58-51\"\n",
        "\n",
        "# 각 클래스에서 하나의 약물을 선택합니다.\n",
        "drugs = [\n",
        "    \"A CN Gel(Topical) 20gmA CN Soap 75gm\" , # Class 0\n",
        "    \"Addnok Tablet 20'S\" , # Class 1\n",
        "    \"ABICET M Tablet 10's\" , # Class 2\n",
        "]\n",
        "\n",
        "# 각 약물에 대한 약물 클래스를 반환합니다.\n",
        "for drug_name in drugs:\n",
        "    prompt = \"Drug: {} \\n Malady:\" . format (drug_name)\n",
        "    response = openai.Completion.create( model = model, prompt = prompt, temperature = 1 , max_tokens = 1 , )\n",
        "\n",
        "    # 생성된 텍스트를 출력합니다.\n",
        "    drug_class = response.choices[ 0 ].text\n",
        "\n",
        "    # 결과는 0, 1, 2 중 하나여야 합니다.\n",
        "    print (drug_class)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### drugs를 변경 후, 테스트 해 보기"
      ],
      "metadata": {
        "id": "8ao2Ns28EUzn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import openai\n",
        "\n",
        "def init_api():\n",
        "    with open ( \"chatgpt.env\" ) as env:\n",
        "        for line in env:\n",
        "            key, value = line.strip().split( \"=\" )\n",
        "            os.environ[key] = value\n",
        "    openai.api_key = os.environ.get( \"API_KEY\" )\n",
        "    openai.organization = os.environ.get( \"ORG_ID\" )\n",
        "\n",
        "init_api()\n",
        "\n",
        "# 모델 ID 설정. 여기서는 사용자의 모델 ID로 변경해야 합니다.\n",
        "model = \"ada:ft-personal:drug-data-2023-08-15-09-58-51\"\n",
        "\n",
        "# 각 클래스에서 하나의 약물을 선택합니다.\n",
        "drugs = [\n",
        "    \"What is 'A CN Gel(Topical) 20gmA CN Soap 75gm' used for?\", # Class 0\n",
        "    \"What is 'Addnok Tablet 20'S' used for?\", # Class 1\n",
        "    \"What is 'ABICET M Tablet 10's' used for?\", # Class 2\n",
        "]\n",
        "\n",
        "class_map = {\n",
        "    0 : \"Acne\" ,\n",
        "    1 : \"Adhd\" ,\n",
        "    2 : \"Allergies\" ,\n",
        "    # ...\n",
        "}\n",
        "\n",
        "\n",
        "\n",
        "# 각 약에 대한 약 클래스를 반환합니다.\n",
        "for drug_name in drugs:\n",
        "    prompt = \"Drug: {} \\n Malady:\" . format (drug_name)\n",
        "    response = openai.Completion.create(\n",
        "        model = model,\n",
        "        prompt = prompt,\n",
        "        temperature = 1 ,\n",
        "        max_tokens = 1 ,\n",
        "    )\n",
        "\n",
        "    response = response.choices[0].text\n",
        "\n",
        "    try :\n",
        "        print (drug_name + \" is used for \" + class_map[ int (response)])\n",
        "    except :\n",
        "        print ( \"I don't know what \" + drug_name + \" is used for.\" )\n",
        "\n",
        "    print ()\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-JtaOjjkG5h7",
        "outputId": "7e4e00dd-8450-4c31-d93c-eb0b8391450c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "What is 'A CN Gel(Topical) 20gmA CN Soap 75gm' used for? is used for Acne\n",
            "\n",
            "What is 'Addnok Tablet 20'S' used for? is used for Adhd\n",
            "\n",
            "What is 'ABICET M Tablet 10's' used for? is used for Allergies\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "53kgvDtAHET4"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}