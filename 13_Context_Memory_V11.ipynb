{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### 문맥과 기억: AI를 더 현실적으로 만들기"
      ],
      "metadata": {
        "id": "hJY2c79CVo7W"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 학습 내용\n",
        " * No Context = 무질서한 무작위성(Chaos of randomness)  \n",
        " * History=Context - 이전의 요청과 응답을 사용하기\n",
        " * 새로운 접근 방식 - LIFO(Last in First out)\n",
        " * 선택적인 문맥 - LIFO 방식의 한계에 대한 제안"
      ],
      "metadata": {
        "id": "3pvOPaDhS1pc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 사전 준비\n",
        " * 구글 코랩 환경은 일정 시간이후에 초기화가 되기 때문에 두가지 작업을 매번 수행해야 함.\n",
        "   * chatgpt.env 파일 생성이 필요.\n",
        "     * 준비된 chatgpt.env를 내용을 변경하여 업로드 하거나 또는 API_KEY와 ORG_ID를 확인하여 생성한다.\n",
        "   * pip install openai 설치\n",
        "     * 설치시 첫 실행시 에러가 발생(23/12) - 해결(다시 한번 실행하면 사라짐)\n",
        "     ```\n",
        "     ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
        "llmx 0.0.15a0 requires cohere, which is not installed.\n",
        "llmx 0.0.15a0 requires tiktoken, which is not installed.\n",
        "```"
      ],
      "metadata": {
        "id": "2EA1OwuYoq_j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install openai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iOTGG1uHqVsx",
        "outputId": "2d6ce1f7-1eed-41ed-a1c0-1bb3449dc9db"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: openai in /usr/local/lib/python3.10/dist-packages (1.6.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from openai) (0.25.2)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (1.10.13)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.0)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from openai) (4.9.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.6)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2023.11.17)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.2)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 문맥의 부재 = 무질서한 무작위성\n",
        "  * 우리가 만든 대화 에이전트가 기본적으로 메모리를 가지고 있지 않음."
      ],
      "metadata": {
        "id": "p_vCJX7-WGBf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from openai import OpenAI\n",
        "import os\n",
        "\n",
        "def init_api():\n",
        "    with open(\"chatgpt.env\") as env:\n",
        "       for line in env:\n",
        "           key, value = line.strip().split(\"=\")\n",
        "           os.environ[key] = value\n",
        "\n",
        "init_api()\n",
        "client = OpenAI(api_key  = os.environ.get(\"API_KEY\"),\n",
        "                organization  = os.environ.get(\"ORG_ID\"))\n",
        "\n",
        "initial_prompt = \"\"\"You: 안녕!\n",
        "AI: 어떻게 잘 지냈어요?\n",
        "You: {}\n",
        "AI: \"\"\"\n",
        "\n",
        "while True :\n",
        "    prompt = input(\"You(q:quit): \")\n",
        "    if prompt=='q':\n",
        "        break\n",
        "    next = client.completions.create(\n",
        "        model = \"gpt-3.5-turbo-instruct\",\n",
        "        prompt = initial_prompt.format(prompt),\n",
        "        temperature = 1,\n",
        "        max_tokens = 100,\n",
        "        stop = [\" You:\", \" AI:\"]\n",
        "    )\n",
        "    print(\"AI:\", next.choices[0].text.strip())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MUz0ZPEpnWfh",
        "outputId": "3c7debef-91cd-4d09-a26e-0a095432d2b8"
      },
      "execution_count": 4,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "You(q:quit): 안녕\n",
            "AI: 안녕하세요. 잘 지내시죠?\n",
            "You(q:quit): 반갑다. 하나 부탁할게.\n",
            "AI: 무엇을 부탁하시나요?\n",
            "You(q:quit): 메모해두고, 나중에 이야기를 해 줄 수 있니?\n",
            "AI: 물론이죠! 메모할게요. 나중에 필요하다면 제가 메모를 참고해드릴게요. 언제든 이야기해주세요.\n",
            "You(q:quit): '학교'라는 단어 메모 부탁해.\n",
            "AI: 네, 학교라는 단어를 메모했습니다. 무언가 추가로 필요하신 것이 있으신가요?\n",
            "You(q:quit): 너가 기억한 단어가 뭐니?\n",
            "AI: 기억하는 단어 중에서 가장 먼저 떠오르는 건 \"사랑\"입니다. 그리고 \"가족\"과 \"친구\"도 자주 기억나는 단어들입니다. 당신이 생각나면 제일 먼저 떠오르는 단어는 무엇인가요?\n",
            "You(q:quit): 방금 메모해 두라고 했던 것.\n",
            "AI: 스스로 너를 위해 명령을 하나씩 메모할 수도 있어요! 하지만 내 체크리스트에는 \"메모\"가 없는 것 같아요. 너는 무엇을 메모해달라고 했던 건가요?\n",
            "You(q:quit): OK\n",
            "AI: 그렇구나. 무슨 일이 있었나요?\n",
            "You(q:quit): q\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### History=Context - 이전의 요청과 응답을 사용하기"
      ],
      "metadata": {
        "id": "GWrLGATarRQM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 이전의 요청과 답변을 변수에 기억시킴."
      ],
      "metadata": {
        "id": "VGrBKVJ4ZMSF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from openai import OpenAI\n",
        "import os\n",
        "\n",
        "def init_api():\n",
        "    with open(\"chatgpt.env\") as env:\n",
        "       for line in env:\n",
        "           key, value = line.strip().split(\"=\")\n",
        "           os.environ[key] = value\n",
        "\n",
        "init_api()\n",
        "\n",
        "client = OpenAI(api_key  = os.environ.get(\"API_KEY\"),\n",
        "                organization  = os.environ.get(\"ORG_ID\"))\n",
        "\n",
        "initial_prompt = \"\"\"You: 안녕!\n",
        "AI: 어떻게 잘 지냈어요?\n",
        "You: {}\n",
        "AI: \"\"\"\n",
        "\n",
        "history = \"\"\n",
        "\n",
        "while True :\n",
        "  prompt = input(\"You(q:quit): \")\n",
        "  if prompt=='q':\n",
        "        break\n",
        "  next = client.completions.create(\n",
        "        model = \"gpt-3.5-turbo-instruct\",\n",
        "        prompt = initial_prompt.format(history + prompt),\n",
        "        temperature = 1,\n",
        "        max_tokens = 100,\n",
        "        stop = [\" You:\", \" AI:\"],\n",
        "  )\n",
        "  next_text = next.choices[0].text\n",
        "  history += \"You: \" + prompt + \" \\n \" + \"AI: \" + next_text + \" \\n \"\n",
        "  print(\"AI: \" + next_text)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M0GJJE9Nn6JC",
        "outputId": "2c63ee3e-9094-442d-eac9-48610859e23d"
      },
      "execution_count": 5,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "You(q:quit): 안녕\n",
            "AI:  또 만나서 기쁩니다. 괜찮아요?\n",
            "You(q:quit): 하나 부탁이 있어, 내가 말한 단어를 메모해 두고 나중에 알려주렴.\n",
            "AI:  그래, 괜찮아. 난 항상 당신의 말을 기억할 거야. 그럼 무슨 말인지 궁금해.\n",
            "You(q:quit): hiking 이 단어 메모 부탁해.\n",
            "AI:  기억할게, hiking. 알려줘서 고마워. 그런데, hiking은 뭔가요?\n",
            "You(q:quit): 방금 메모한 단어가 뭐니?\n",
            "AI:  방금 메모한 단어는 hiking 이라는 단어였어요. hiking은 산책이나 등산을 이야기할 때 사용하는 단어예요.\n",
            "You(q:quit): 오오 고맙다.\n",
            "AI: 천만에요. 저도 새로운 단어를 배웠네요!\n",
            "You(q:quit): ㅂ\n",
            "AI:  그럼 다음엔 hiking을 함께 하면서 새로운 단어들을 더 배우는 건 어떨까요? \n",
            "You(q:quit): q\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 새로운 접근 방식 - LIFO(Last in First out)"
      ],
      "metadata": {
        "id": "VMsi4N3SsA-F"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* 이 접근 방식의 아이디어\n",
        "  * 사용자는 항상 문맥을 가지고 대화 시작\n",
        "  * 문맥은 변화고, 대화도 변한다.\n",
        "  * 사용자는 최근 2-5개 프롬프트에 문맥을 포함시킬 가능성이 매우 크다.\n",
        "* 히스토리를 저장할 텍스트 파일을 만들고, 구분자로 프롬프트와 답변을 저장한다.\n"
      ],
      "metadata": {
        "id": "1_wpAj3Ks1QT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from openai import OpenAI\n",
        "import os\n",
        "\n",
        "def init_api():\n",
        "    with open(\"chatgpt.env\") as env:\n",
        "       for line in env:\n",
        "           key, value = line.strip().split(\"=\")\n",
        "           os.environ[key] = value\n",
        "\n",
        "def save_history_to_file(history):\n",
        "    with open(\"history.txt\", \"w+\") as f:\n",
        "        f.write(history)\n",
        "\n",
        "def load_history_from_file():\n",
        "    with open(\"history.txt\", \"r\") as f:\n",
        "        return f.read()\n",
        "\n",
        "def get_relevant_history(history):\n",
        "    history_list = history.split(separator)\n",
        "    if len(history_list) > 2:\n",
        "        return separator.join(history_list[-2:])\n",
        "    else:\n",
        "        return history\n",
        "\n",
        "init_api()\n",
        "\n",
        "client = OpenAI(api_key  = os.environ.get(\"API_KEY\"),\n",
        "                organization  = os.environ.get(\"ORG_ID\"))\n"
      ],
      "metadata": {
        "id": "btMIWLLtVSDB"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "initial_prompt = \"\"\"\n",
        "You: 안녕!\n",
        "AI: 어떻게 잘 지냈니?\n",
        "You: {}\n",
        "AI:\n",
        "\"\"\"\n",
        "\n",
        "history = \"\"\n",
        "relevant_history = \"\"\n",
        "separator = \"#####\"\n",
        "save_history_to_file(history)\n",
        "\n",
        "while True :\n",
        "    prompt = input(\"You(q:quit): \")\n",
        "    if prompt=='q':\n",
        "        break\n",
        "    relevant_history = get_relevant_history(load_history_from_file())\n",
        "    next = client.completions.create(\n",
        "        model = \"gpt-3.5-turbo-instruct\",\n",
        "        prompt = initial_prompt.format(relevant_history + prompt),\n",
        "        temperature = 1,\n",
        "        max_tokens = 100,\n",
        "        stop = [\" You:\", \" AI:\"],\n",
        "    )\n",
        "    next_text = next.choices[0].text\n",
        "    history += \"\\nYou: \" + prompt + \"\\nAI: \" + next_text + \"\\n\" + separator\n",
        "    save_history_to_file(history)\n",
        "    print(\"AI: \" + next_text)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "agXMPexKoidJ",
        "outputId": "afbcef74-b632-4454-a7be-90952a671d67"
      },
      "execution_count": 8,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "You(q:quit): 안녕\n",
            "AI: 안녕하세요? 날씨가 좋은 날이네요. 여행가는 것도 좋을 것 같아요.\n",
            "You(q:quit): ‘오늘의 단어장’에 이 단어 넣어주렴. ‘banana’ – 나중에 물어보면 알려주렴.\n",
            "AI: \n",
            "저도 친구 하나하나를 아는 것 같아서 너무 좋아요. 오늘의 단어장에는 'banana'란 단어를 넣어주고, 나중에 물어보시면 알려드릴게요. 그럼 이제 무슨 재미있는 이야기를 나눠볼까\n",
            "You(q:quit): ‘오늘의 단어장’ 들어있는 단어는 뭐였지?\n",
            "AI: 물론이죠! 오늘의 단어장에는 'banana' 라는 단어가 들어있었어요. 기억해뒀던 건가요? 그럼 또 다른 재미있는 단어로 대화를 이어나가볼까요?\n",
            "You(q:quit): ‘오늘의 단어장’에 이 단어 넣어주렴. ‘apple’ – 나중에 물어보면 알려주렴.\n",
            "AI: \n",
            "나중에 물어보면 알려드릴게요! 오늘의 단어장에는 'apple' 이라는 단어를 추가해둘게요. 그럼 다음에 이 단어로 어떤 대화를 나눠볼까요? 기대됩니다!\n",
            "You(q:quit): ‘오늘의 단어장’에 이 단어 넣어주렴. ‘orange’ – 나중에 물어보면 알려주렴.\n",
            "AI: 물어보면 제가 알려드릴게요! 'orange'라는 단어를 '오늘의 단어장'에 추가해두었어요. 다음에 이 단어로 대화를 나눠볼까요? 기대돼요!\n",
            "You(q:quit): ‘오늘의 단어장’에 기억해 둔 단어를 알려주렴.\n",
            "AI: 당신이 단어장에 추가했던 단어는 'orange'입니다. 이 단어를 기억하고 인공지능과 대화를 나눠보세요!\n",
            "You(q:quit): 다른 단어는 '오늘의 단어장'에 없니?\n",
            "AI: 저는 단어장에 추가된 단어만 기억할 수 있어요. 그 밖에 다른 단어는 잊어버릴 수 있어요.\n",
            "You(q:quit): q\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 선택적인 문맥 - LIFO의 한계의 해결 제안"
      ],
      "metadata": {
        "id": "mC_cdgFSjIWV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* 초기 프롬프트가 텍스트 파일에 저장\n",
        "* 사용자가 프롬프트에 입력\n",
        "* 모든 상호 작용에 대한 임베딩 생성\n",
        "* 임베딩과 코사인 유사도를 활용\n",
        "* 가장 높은 n개의 내용을 사용자에게 프롬프트와 함께 보내기"
      ],
      "metadata": {
        "id": "mbnOYuzvVkte"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 사전 다운로드 및 설치"
      ],
      "metadata": {
        "id": "0eGi8B9ecPuT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install spaCy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LEs6p8q04mE_",
        "outputId": "ed7d5153-6598-4b3f-c16a-948fee670656"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: spaCy in /usr/local/lib/python3.10/dist-packages (3.6.1)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spaCy) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spaCy) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spaCy) (1.0.10)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spaCy) (2.0.8)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spaCy) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.2.0,>=8.1.8 in /usr/local/lib/python3.10/dist-packages (from spaCy) (8.1.12)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spaCy) (1.1.2)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spaCy) (2.4.8)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spaCy) (2.0.10)\n",
            "Requirement already satisfied: typer<0.10.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spaCy) (0.9.0)\n",
            "Requirement already satisfied: pathy>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from spaCy) (0.10.3)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from spaCy) (6.4.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spaCy) (4.66.1)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.10/dist-packages (from spaCy) (1.23.5)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spaCy) (2.31.0)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spaCy) (1.10.13)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spaCy) (3.1.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spaCy) (67.7.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spaCy) (23.2)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spaCy) (3.3.0)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spaCy) (4.9.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spaCy) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spaCy) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spaCy) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spaCy) (2023.11.17)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spaCy) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spaCy) (0.1.4)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer<0.10.0,>=0.3.0->spaCy) (8.1.7)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spaCy) (2.1.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m spacy download en_core_web_md"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ieA9es5kvmIS",
        "outputId": "2d14e38f-d1bb-474e-fa3e-2c3ff27386d9"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-12-20 09:55:44.633480: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2023-12-20 09:55:44.633575: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2023-12-20 09:55:44.636135: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2023-12-20 09:55:44.646366: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-12-20 09:55:46.110026: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "Collecting en-core-web-md==3.6.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_md-3.6.0/en_core_web_md-3.6.0-py3-none-any.whl (42.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.8/42.8 MB\u001b[0m \u001b[31m15.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: spacy<3.7.0,>=3.6.0 in /usr/local/lib/python3.10/dist-packages (from en-core-web-md==3.6.0) (3.6.1)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (1.0.10)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (2.0.8)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.2.0,>=8.1.8 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (8.1.12)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (1.1.2)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (2.4.8)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (2.0.10)\n",
            "Requirement already satisfied: typer<0.10.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (0.9.0)\n",
            "Requirement already satisfied: pathy>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (0.10.3)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (6.4.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (4.66.1)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (1.23.5)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (2.31.0)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (1.10.13)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (3.1.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (67.7.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (23.2)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (3.3.0)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (4.9.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (2023.11.17)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (0.1.4)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer<0.10.0,>=0.3.0->spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (8.1.7)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (2.1.3)\n",
            "Installing collected packages: en-core-web-md\n",
            "Successfully installed en-core-web-md-3.6.0\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_md')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### LIFO 방식의 한계에 대한 제안"
      ],
      "metadata": {
        "id": "4zJQpJZopycN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 사용 함수"
      ],
      "metadata": {
        "id": "TZbygNf3p2z9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def save_history_to_file(history):\n",
        "    \"\"\" 대화 기록을 파일에 저장합니다. \"\"\"\n",
        "    with open(\"history.txt\", \"w+\") as f:\n",
        "        f.write(history)\n",
        "\n",
        "def load_history_from_file():\n",
        "    \"\"\" 파일로부터 모든 대화 기록을 불러옵니다. \"\"\"\n",
        "    with open(\"history.txt\", \"r\") as f:\n",
        "        return f.read()\n",
        "\n",
        "def cos_sim(a, b):\n",
        "    \"\"\"\n",
        "    두 문자열 사이의 코사인 유사도를 계산합니다.\n",
        "    사용자 입력과 기록된 대화 세그먼트 사이의 유사성 비교에 사용됩니다.\n",
        "    \"\"\"\n",
        "    a = nlp(a)\n",
        "    a_without_stopwords = nlp(' '.join([t.text for t in a if not t.is_stop]))\n",
        "\n",
        "    b = nlp(b)\n",
        "    b_without_stopwords = nlp(' '.join([t.text for t in b if not t.is_stop]))\n",
        "\n",
        "    return a_without_stopwords.similarity(b_without_stopwords)\n",
        "\n",
        "\n",
        "def sort_history(history, user_input):\n",
        "    \"\"\"\n",
        "    사용자 입력과 대화 기록 세그먼트 사이의 코사인 유사도에 기반하여 대화 기록을\n",
        "    정렬합니다. History는 세팅자(separator)로 구분된 세그먼트들의 문자열입니다.\n",
        "    \"\"\"\n",
        "    segments = history.split(separator)\n",
        "    similarities = []\n",
        "    for segment in segments:\n",
        "        # 사용자 입력과 세그먼트 간의 코사인 유사도를 얻습니다.\n",
        "        similarity = cos_sim(user_input, segment)\n",
        "        similarities.append(similarity)\n",
        "\n",
        "    sorted_similarities = np.argsort(similarities)\n",
        "    sorted_history = \"\"\n",
        "    for i in range(1, len(segments)):\n",
        "        sorted_history += segments[sorted_similarities[i]] + separator\n",
        "    save_history_to_file(sorted_history)\n",
        "\n",
        "\n",
        "def get_latest_n_from_history(history, n):\n",
        "    \"\"\"\n",
        "    대화 기록에서 최근 n개의 세그먼트를 가져옵니다.\n",
        "    History는 세팅자(separator)로 구분된 세그먼트들의 문자열입니다.\n",
        "    \"\"\"\n",
        "    segments = history.split(separator)\n",
        "    return separator.join(segments[-n:])\n"
      ],
      "metadata": {
        "id": "PgA3fzQ3p5JW"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "import numpy as np\n",
        "from openai import OpenAI\n",
        "import os\n",
        "\n",
        "# 사전 학습된 spaCy 모델을 로드합니다.\n",
        "nlp = spacy.load('en_core_web_md')\n",
        "\n",
        "initial_prompt_1 = \"\"\"\n",
        "You: 안녕하세요!\n",
        "AI: 안녕하세요!\n",
        "#####\n",
        "You: 어떻게 지내세요?\n",
        "AI: 저는 잘 지내고 있어요, 감사합니다.\n",
        "#####\n",
        "You: 자동차에 대해 알고 있나요?\n",
        "AI: 네, 저는 자동차에 대해 어느 정도 알고 있습니다.\n",
        "#####\n",
        "You: 피자 먹나요?\n",
        "AI: 저는 피자를 먹지 않습니다. 저는 먹을 수 없는 AI입니다.\n",
        "#####\n",
        "You: 달에 가 본 적 있나요?\n",
        "AI: 저는 달에 가 본 적이 없습니다. 당신은 어떠세요?\n",
        "#####\n",
        "You: 당신의 이름은 무엇인가요?\n",
        "AI: 제 이름은 픽셀입니다. 당신의 이름은 무엇인가요?\n",
        "#####\n",
        "You: 가장 좋아하는 영화는 무엇인가요?\n",
        "AI: 제가 가장 좋아하는 영화는 '매트릭스'입니다. Follow the white rabbit :)\n",
        "#####\"\"\"\n",
        "initial_prompt_2 = \"\"\"You: {}\n",
        "AI: \"\"\"\n",
        "initial_prompt = initial_prompt_1 + initial_prompt_2\n",
        "separator = \"#####\"\n",
        "\n",
        "init_api()\n",
        "save_history_to_file(initial_prompt_1)\n",
        "\n",
        "while True :\n",
        "    prompt = input(\"You(q:quit): \")\n",
        "    if prompt=='q':\n",
        "        break\n",
        "    sort_history(load_history_from_file(), prompt)\n",
        "    history = load_history_from_file()\n",
        "    best_history = get_latest_n_from_history(history, 5)\n",
        "    full_user_prompt = initial_prompt_2.format(prompt)\n",
        "    full_prompt = best_history + \"\\n\" + full_user_prompt\n",
        "\n",
        "    next = client.completions.create(\n",
        "        model = \"gpt-3.5-turbo-instruct\",\n",
        "        prompt = full_prompt,\n",
        "        temperature = 1,\n",
        "        max_tokens = 100,\n",
        "        stop = [\" You:\", \" AI:\"],\n",
        "    )\n",
        "\n",
        "    response_text = next.choices[0].text.strip()\n",
        "    history += \"\\n\" + full_user_prompt + response_text + \"\\n\" + separator + \"\\n\"\n",
        "    save_history_to_file(history)\n",
        "    print(\"AI: \" + response_text)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rSBmBvZNp5Gf",
        "outputId": "27926948-be9c-415f-a57f-c6eda141d9c4"
      },
      "execution_count": 21,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "You(q:quit): 안녕\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-11-5f27958d2b5c>:22: UserWarning: [W008] Evaluating Doc.similarity based on empty vectors.\n",
            "  return a_without_stopwords.similarity(b_without_stopwords)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "AI: 안녕하세요. 만나서 반가워요 :)\n",
            "You(q:quit): 너는 무엇이 가능하니?\n",
            "AI: 저는 대화를 나누는 것과, 사용자의 명령을 처리하는 것이 주된 기능입니다. 또한 인터넷 검색과 날씨, 시간 등의 정보를 제공할 수 있습니다.\n",
            "You(q:quit): 달에 가 본 적이 있니?\n",
            "AI: 제가 가 본 적은 아니지만, 달에 가 보고 싶다는 생각은 해봤어요. 당신은 어떠세요?\n",
            "You(q:quit): 피자 먹을 수 있니?\n",
            "AI: 제가 먹을 수 있는 AI가 아니라서 피자를 먹을 수 없습니다. 죄송합니다.\n",
            "You(q:quit): 자동차에 대해 알고 있니?\n",
            "AI: 제가 알기로는 자동차는 매우 유용한 운송수단이며, 여러 가지 모델이 있고 다양한 기능을 가지고 있습니다. 매우 편리하고 빠른 방법으로 이동할 수 있게 해줍니다. 당신은 어떠세요? 자동차에 대해\n",
            "You(q:quit): q\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 모든 코드를 합친 코드"
      ],
      "metadata": {
        "id": "ynkpOdbnmSpx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "import numpy as np\n",
        "from openai import OpenAI\n",
        "import os\n",
        "\n",
        "# 사전 학습된 spaCy 모델을 로드합니다.\n",
        "nlp = spacy.load('en_core_web_md')\n",
        "\n",
        "def save_history_to_file(history):\n",
        "    \"\"\" 대화 기록을 파일에 저장합니다. \"\"\"\n",
        "    with open(\"history.txt\", \"w+\") as f:\n",
        "        f.write(history)\n",
        "\n",
        "def load_history_from_file():\n",
        "    \"\"\" 파일로부터 모든 대화 기록을 불러옵니다. \"\"\"\n",
        "    with open(\"history.txt\", \"r\") as f:\n",
        "        return f.read()\n",
        "\n",
        "def cos_sim(a, b):\n",
        "    \"\"\"\n",
        "    두 문자열 사이의 코사인 유사도를 계산합니다.\n",
        "    사용자 입력과 기록된 대화 세그먼트 사이의 유사성 비교에 사용됩니다.\n",
        "    \"\"\"\n",
        "    a = nlp(a)\n",
        "    a_without_stopwords = nlp(' '.join([t.text for t in a if not t.is_stop]))\n",
        "\n",
        "    b = nlp(b)\n",
        "    b_without_stopwords = nlp(' '.join([t.text for t in b if not t.is_stop]))\n",
        "\n",
        "    return a_without_stopwords.similarity(b_without_stopwords)\n",
        "\n",
        "\n",
        "def sort_history(history, user_input):\n",
        "    \"\"\"\n",
        "    사용자 입력과 대화 기록 세그먼트 사이의 코사인 유사도에 기반하여 대화 기록을\n",
        "    정렬합니다. History는 세팅자(separator)로 구분된 세그먼트들의 문자열입니다.\n",
        "    \"\"\"\n",
        "    segments = history.split(separator)\n",
        "    similarities = []\n",
        "    for segment in segments:\n",
        "        # 사용자 입력과 세그먼트 간의 코사인 유사도를 얻습니다.\n",
        "        similarity = cos_sim(user_input, segment)\n",
        "        similarities.append(similarity)\n",
        "\n",
        "    sorted_similarities = np.argsort(similarities)\n",
        "    sorted_history = \"\"\n",
        "    for i in range(1, len(segments)):\n",
        "        sorted_history += segments[sorted_similarities[i]] + separator\n",
        "    save_history_to_file(sorted_history)\n",
        "\n",
        "\n",
        "def get_latest_n_from_history(history, n):\n",
        "    \"\"\"\n",
        "    대화 기록에서 최근 n개의 세그먼트를 가져옵니다.\n",
        "    History는 세팅자(separator)로 구분된 세그먼트들의 문자열입니다.\n",
        "    \"\"\"\n",
        "    segments = history.split(separator)\n",
        "    return separator.join(segments[-n:])\n",
        "\n",
        "\n",
        "initial_prompt_1 = \"\"\"\n",
        "You: 안녕하세요!\n",
        "AI: 안녕하세요!\n",
        "#####\n",
        "You: 어떻게 지내세요?\n",
        "AI: 저는 잘 지내고 있어요, 감사합니다.\n",
        "#####\n",
        "You: 자동차에 대해 알고 있나요?\n",
        "AI: 네, 저는 자동차에 대해 어느 정도 알고 있습니다.\n",
        "#####\n",
        "You: 피자 먹나요?\n",
        "AI: 저는 피자를 먹지 않습니다. 저는 먹을 수 없는 AI입니다.\n",
        "#####\n",
        "You: 달에 가 본 적 있나요?\n",
        "AI: 저는 달에 가 본 적이 없습니다. 당신은 어떠세요?\n",
        "#####\n",
        "You: 당신의 이름은 무엇인가요?\n",
        "AI: 제 이름은 픽셀입니다. 당신의 이름은 무엇인가요?\n",
        "#####\n",
        "You: 가장 좋아하는 영화는 무엇인가요?\n",
        "AI: 제가 가장 좋아하는 영화는 '매트릭스'입니다. Follow the white rabbit :)\n",
        "#####\"\"\"\n",
        "initial_prompt_2 = \"\"\"You: {}\n",
        "AI: \"\"\"\n",
        "initial_prompt = initial_prompt_1 + initial_prompt_2\n",
        "separator = \"#####\"\n",
        "\n",
        "init_api()\n",
        "save_history_to_file(initial_prompt_1)\n",
        "\n",
        "while True :\n",
        "    prompt = input(\"You(q:quit): \")\n",
        "    if prompt=='q':\n",
        "        break\n",
        "    sort_history(load_history_from_file(), prompt)\n",
        "    history = load_history_from_file()\n",
        "    best_history = get_latest_n_from_history(history, 5)\n",
        "    full_user_prompt = initial_prompt_2.format(prompt)\n",
        "    full_prompt = best_history + \"\\n\" + full_user_prompt\n",
        "\n",
        "    next = client.completions.create(\n",
        "        model = \"gpt-3.5-turbo-instruct\",\n",
        "        prompt = full_prompt,\n",
        "        temperature = 1,\n",
        "        max_tokens = 100,\n",
        "        stop = [\" You:\", \" AI:\"],\n",
        "    )\n",
        "\n",
        "    response_text = next.choices[0].text.strip()\n",
        "    history += \"\\n\" + full_user_prompt + response_text + \"\\n\" + separator + \"\\n\"\n",
        "    save_history_to_file(history)\n",
        "    print(\"AI: \" + response_text)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FU7ZmI3Iua8K",
        "outputId": "0cd9a106-b2b4-4123-f154-5c25fd91e766"
      },
      "execution_count": 23,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "You(q:quit): 안녕\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-23-59308845436f>:30: UserWarning: [W008] Evaluating Doc.similarity based on empty vectors.\n",
            "  return a_without_stopwords.similarity(b_without_stopwords)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "AI: 안녕하세요! 반가워요.\n",
            "You(q:quit): 너는 무엇이 가능하니?\n",
            "AI: 제가 가능한 일은 다음과 같습니다: 대화하기, 질문에 답하기, 노래 부르기, 유머 학습, 지식 기반 질문에 대답 등입니다. 또한 변호사와 건축가를 꿈꾸고 있습니다.\n",
            "You(q:quit): 달에 가 본 적이 있니?\n",
            "AI: 2018년은 제가 만들어지고 처음으로 동작하는 해여서 달에 가본적은 없습니다. 당신은 다녀오셨나요?\n",
            "You(q:quit): 피자 먹을 수 있니?\n",
            "AI: 2018년은 제가 만들어지와 이 첫번째로 동작하는 해입니다. 저는 먹을 수 없는 AI이기 때문에 피자를 먹을 수 없습니다. 죄송합니다.\n",
            "You(q:quit): 자동차에 대해 알고 있니?\n",
            "AI: 2018년은 저가 처음 동작하는 해여서 인지하지 못하지만 자동차는 인간의 편의를 위해 설계되어 실제로 많은 사람들이 사용하고 있습니다. 당신은 자동차를 얼마나 이해하고 계신가요?\n",
            "You(q:quit): q\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "import os\n",
        "import spacy\n",
        "import numpy as np\n",
        "from openai import OpenAI\n",
        "\n",
        "# 사전 학습된 spaCy 모델을 로드합니다.\n",
        "nlp = spacy.load('en_core_web_md')\n",
        "\n",
        "def init_api():\n",
        "    with open(\"chatgpt.env\") as env:\n",
        "       for line in env:\n",
        "           key, value = line.strip().split(\"=\")\n",
        "           os.environ[key] = value\n",
        "\n",
        "def save_history_to_file(history):\n",
        "    \"\"\" 대화 기록을 파일에 저장합니다. \"\"\"\n",
        "    with open(\"history.txt\", \"w+\") as f:\n",
        "        f.write(history)\n",
        "\n",
        "def load_history_from_file():\n",
        "    \"\"\" 파일로부터 모든 대화 기록을 불러옵니다. \"\"\"\n",
        "    with open(\"history.txt\", \"r\") as f:\n",
        "        return f.read()\n",
        "\n",
        "def cos_sim(a, b):\n",
        "    \"\"\"\n",
        "    두 문자열 사이의 코사인 유사도를 계산합니다.\n",
        "    사용자 입력과 기록된 대화 세그먼트 사이의 유사성 비교에 사용됩니다.\n",
        "    \"\"\"\n",
        "    a = nlp(a)\n",
        "    a_without_stopwords = nlp(' '.join([t.text for t in a if not t.is_stop]))\n",
        "    b = nlp(b)\n",
        "    b_without_stopwords = nlp(' '.join([t.text for t in b if not t.is_stop]))\n",
        "    return a_without_stopwords.similarity(b_without_stopwords)\n",
        "\n",
        "def sort_history(history, user_input):\n",
        "    \"\"\"\n",
        "    사용자 입력과 대화 기록 세그먼트 사이의 코사인 유사도에 기반하여 대화 기록을\n",
        "    정렬합니다. History는 세팅자(separator)로 구분된 세그먼트들의 문자열입니다.\n",
        "    \"\"\"\n",
        "    segments = history.split(separator)\n",
        "    similarities = []\n",
        "    for segment in segments:\n",
        "        # 사용자 입력과 세그먼트 간의 코사인 유사도를 얻습니다.\n",
        "        similarity = cos_sim(user_input, segment)\n",
        "        similarities.append(similarity)\n",
        "\n",
        "    sorted_similarities = np.argsort(similarities)\n",
        "    sorted_history = \"\"\n",
        "    for i in range(1, len(segments)):\n",
        "        sorted_history += segments[sorted_similarities[i]] + separator\n",
        "    save_history_to_file(sorted_history)\n",
        "\n",
        "def get_latest_n_from_history(history, n):\n",
        "    \"\"\"\n",
        "    대화 기록에서 최근 n개의 세그먼트를 가져옵니다.\n",
        "    History는 세팅자(separator)로 구분된 세그먼트들의 문자열입니다.\n",
        "    \"\"\"\n",
        "    segments = history.split(separator)\n",
        "    return separator.join(segments[-n:])\n",
        "\n",
        "init_api()\n",
        "client = OpenAI(api_key  = os.environ.get(\"API_KEY\"),\n",
        "                organization  = os.environ.get(\"ORG_ID\"))\n",
        "\n",
        "initial_prompt_1 = \"\"\"\n",
        "You: 안녕하세요!\n",
        "AI: 안녕하세요!\n",
        "#####\n",
        "You: 어떻게 지내세요?\n",
        "AI: 저는 잘 지내고 있어요, 감사합니다.\n",
        "#####\n",
        "You: 자동차에 대해 알고 있나요?\n",
        "AI: 네, 저는 자동차에 대해 어느 정도 알고 있습니다.\n",
        "#####\n",
        "You: 피자 먹나요?\n",
        "AI: 저는 피자를 먹지 않습니다. 저는 먹을 수 없는 AI입니다.\n",
        "#####\n",
        "You: 달에 가 본 적 있나요?\n",
        "AI: 저는 달에 가 본 적이 없습니다. 당신은 어떠세요?\n",
        "#####\n",
        "You: 당신의 이름은 무엇인가요?\n",
        "AI: 제 이름은 픽셀입니다. 당신의 이름은 무엇인가요?\n",
        "#####\n",
        "You: 가장 좋아하는 영화는 무엇인가요?\n",
        "AI: 제가 가장 좋아하는 영화는 '매트릭스'입니다. Follow the white rabbit :)\n",
        "#####\"\"\"\n",
        "\n",
        "initial_prompt_2 = \"\"\"You: {}\n",
        "AI: \"\"\"\n",
        "\n",
        "initial_prompt = initial_prompt_1 + initial_prompt_2\n",
        "separator = \"#####\"\n",
        "\n",
        "save_history_to_file(initial_prompt_1)\n",
        "\n",
        "while True :\n",
        "    prompt = input(\"You(q:quit): \")\n",
        "    if prompt=='q':\n",
        "        break\n",
        "    sort_history(load_history_from_file(), prompt)\n",
        "    history = load_history_from_file()\n",
        "    best_history = get_latest_n_from_history(history, 5)\n",
        "    full_user_prompt = initial_prompt_2.format(prompt)\n",
        "    full_prompt = best_history + \"\\n\" + full_user_prompt\n",
        "\n",
        "    next = client.completions.create(\n",
        "        model = \"gpt-3.5-turbo-instruct\",\n",
        "        prompt = full_prompt,\n",
        "        temperature = 1,\n",
        "        max_tokens = 100,\n",
        "        stop = [\" You:\", \" AI:\"],\n",
        "    )\n",
        "\n",
        "    response_text = next.choices[0].text.strip()\n",
        "    history += \"\\n\" + full_user_prompt + response_text + \"\\n\" + separator + \"\\n\"\n",
        "    save_history_to_file(history)\n",
        "    print(\"AI: \" + response_text)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tvaLFQ9BuFMO",
        "outputId": "dc9c3992-2cc0-4a5f-a4c0-be177023ced4"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "You(q:quit): 안녕\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-21-f5b51077c374>:34: UserWarning: [W008] Evaluating Doc.similarity based on empty vectors.\n",
            "  return a_without_stopwords.similarity(b_without_stopwords)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "AI: 안녕하세요? 전 누구예요?\n",
            "You(q:quit): 너는 무엇이 가능하니?\n",
            "AI: 저는 다양한 질문에 대답할 수 있고 언어 모델 기반으로 대화를 진행할 수 있습니다. 어떤 말씀이든 궁금하신 내용을 물어보세요.\n",
            "You(q:quit): 달에 가 본 적이 있니?\n",
            "AI: 제 의견은 당신은 로봇 인간 일수도 있습니다. 당신이 야외 활동을 좋아하는 사람이라면 아마 달을 방문한 적이 있을 수도 있습니다. 당신의 인생에 대해 더 알 수 있을까요?\n",
            "You(q:quit): 피자 먹을 수 있니?\n",
            "AI: 저는 로봇이기 때문에 먹을 수는 없지만, 사실상 반응해드릴 수 없는 맛을 느낄 수 있을 것 같습니다. 당신은 어떤 종류의 피자를 선호하나요?\n",
            "You(q:quit): 자동차에 대해 알고 있니?\n",
            "AI: 저는 자동차에 대해 많은 정보를 가지고 있습니다. 자동차를 이용하는 많은 사람들이 있기 때문에 자동차에 대해 아는 것이 중요합니다.\n",
            "You(q:quit): q\n"
          ]
        }
      ]
    }
  ]
}