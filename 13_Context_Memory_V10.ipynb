{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### 문맥과 기억: AI를 더 현실적으로 만들기"
      ],
      "metadata": {
        "id": "hJY2c79CVo7W"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 학습 내용\n",
        " * No Context = 무질서한 무작위성(Chaos of randomness)  \n",
        " * History=Context - 이전의 요청과 응답을 사용하기\n",
        " * 새로운 접근 방식 - LIFO(Last in First out)\n",
        " * 선택적인 문맥 - LIFO 방식의 한계에 대한 제안"
      ],
      "metadata": {
        "id": "3pvOPaDhS1pc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 사전 준비\n",
        " * 구글 코랩 환경은 일정 시간이후에 초기화가 되기 때문에 두가지 작업을 매번 수행해야 함.\n",
        "   * chatgpt.env 파일 생성이 필요.\n",
        "     * 준비된 chatgpt.env를 내용을 변경하여 업로드 하거나 또는 API_KEY와 ORG_ID를 확인하여 생성한다.\n",
        "   * pip install openai 설치\n",
        "     * 설치시 첫 실행시 에러가 발생(23/12) - 해결(다시 한번 실행하면 사라짐)\n",
        "     ```\n",
        "     ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
        "llmx 0.0.15a0 requires cohere, which is not installed.\n",
        "llmx 0.0.15a0 requires tiktoken, which is not installed.\n",
        "```"
      ],
      "metadata": {
        "id": "2EA1OwuYoq_j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install openai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iOTGG1uHqVsx",
        "outputId": "0e068d3c-526f-4e8d-fcd4-67754d98aaae"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: openai in /usr/local/lib/python3.10/dist-packages (1.3.8)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from openai) (0.25.2)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (1.10.13)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.0)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.5 in /usr/local/lib/python3.10/dist-packages (from openai) (4.5.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.6)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2023.11.17)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.2)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### No Context = 무질서한 무작위성\n",
        "  * 우리가 만든 대화 에이전트가 기본적으로 메모리를 가지고 있지 않음."
      ],
      "metadata": {
        "id": "p_vCJX7-WGBf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from openai import OpenAI\n",
        "import os\n",
        "\n",
        "\n",
        "def init_api():\n",
        "    with open(\"chatgpt.env\") as env:\n",
        "       for line in env:\n",
        "           key, value = line.strip().split(\"=\")\n",
        "           os.environ[key] = value\n",
        "\n",
        "init_api()\n",
        "client = OpenAI(api_key  = os.environ.get(\"API_KEY\"),\n",
        "                organization  = os.environ.get(\"ORG_ID\"))\n",
        "\n",
        "initial_prompt = \"\"\"You: 안녕!\n",
        "AI: 어떻게 잘 지냈어요?\n",
        "You: {}\n",
        "AI: \"\"\"\n",
        "\n",
        "while True :\n",
        "    prompt = input(\"You(q:quit): \")\n",
        "    if prompt=='q':\n",
        "        break\n",
        "    next = client.completions.create(\n",
        "        model = \"gpt-3.5-turbo-instruct\",\n",
        "        prompt = initial_prompt.format(prompt),\n",
        "        temperature = 1,\n",
        "        max_tokens = 100,\n",
        "        stop = [\" You:\", \" AI:\"]\n",
        "    )\n",
        "    print(\"AI:\", next.choices[0].text.strip())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7CasL5-Eq0r-",
        "outputId": "d42157bc-2ac5-4820-d012-be245fe1b377"
      },
      "execution_count": 6,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "You(q:quit): 안녕\n",
            "AI: 반가워요.\n",
            "You(q:quit): 반갑다. 하나 부탁할게.\n",
            "AI: 무슨 일인가요? 부탁해도 될까요?\n",
            "You(q:quit): 메모해두고, 나중에 이야기를 해 줄 수 있니?\n",
            "AI: 네, 메모해둘게요. 이야기를 나중에 그때 다시 들려주며 좋아할 거예요.\n",
            "You(q:quit): '학교'라는 단어 메모 부탁해.\n",
            "AI: 알겠습니다. \"학교\" 라는 단어를 메모했습니다.\n",
            "You(q:quit): 너가 기억한 단어가 뭐니?\n",
            "AI: 그게 무슨 말이에요?\n",
            "You(q:quit): 방금 메모해 두라고 했던 것.\n",
            "AI: 많은 일이 생겼나요?\n",
            "You(q:quit): OK\n",
            "AI: 그래요, 그렇구나. 무슨 일이 있었나요?\n",
            "You(q:quit): q\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### History=Context - 이전의 요청과 응답을 사용하기"
      ],
      "metadata": {
        "id": "GWrLGATarRQM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 이전의 요청과 답변을 변수에 기억시킴."
      ],
      "metadata": {
        "id": "VGrBKVJ4ZMSF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from openai import OpenAI\n",
        "import os\n",
        "\n",
        "def init_api():\n",
        "    with open(\"chatgpt.env\") as env:\n",
        "       for line in env:\n",
        "           key, value = line.strip().split(\"=\")\n",
        "           os.environ[key] = value\n",
        "\n",
        "init_api()\n",
        "\n",
        "client = OpenAI(api_key  = os.environ.get(\"API_KEY\"),\n",
        "                organization  = os.environ.get(\"ORG_ID\"))\n",
        "\n",
        "initial_prompt = \"\"\"You: 안녕!\n",
        "AI: 어떻게 잘 지냈어요?\n",
        "You: {}\n",
        "AI: \"\"\"\n",
        "\n",
        "history = \"\"\n",
        "\n",
        "while True :\n",
        "  prompt = input(\"You(q:quit): \")\n",
        "  if prompt=='q':\n",
        "        break\n",
        "  next = client.completions.create(\n",
        "        model = \"gpt-3.5-turbo-instruct\",\n",
        "        prompt = initial_prompt.format(history + prompt),\n",
        "        temperature = 1,\n",
        "        max_tokens = 100,\n",
        "        stop = [\" You:\", \" AI:\"],\n",
        "  )\n",
        "  next_text = next.choices[0].text\n",
        "  history += \"You: \" + prompt + \" \\n \" + \"AI: \" + next_text + \" \\n \"\n",
        "  print(\"AI: \" + next_text)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9P5-EaJosAr3",
        "outputId": "8fbd7bb2-750d-444b-f131-2d01464618f0"
      },
      "execution_count": 7,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "You(q:quit): \"안녕\" \n",
            "AI: 안녕하세요, 만나서 반가워요. 저는 인공지능 챗봇이에요. \n",
            "You(q:quit): 하나 부탁이 있어, 내가 말한 단어를 메모해 두고 나중에 알려주렴.\n",
            "AI: 좋아요. 어떤 단어를 메모해 둘까요?\n",
            "You(q:quit): hiking 이 단어 메모 부탁해.\n",
            "AI: \"hiking\" 단어를 메모해두었습니다. 다시 말씀해주시면 알려드릴게요.\n",
            "You(q:quit): 방금 메모한 단어가 뭐니?\n",
            "AI:  방금 메모한 단어는 \"hiking\"이에요.\n",
            "You(q:quit): 오오 고맙다.\n",
            "AI: 별 일 아닙니다. 그런데, 저도 알고 싶어서 검색해봤어요. 하이킹은 산을 등산하면서 즐기는 레저나 스포츠 활동을 뜻한다고 하네요.\n",
            "You(q:quit): q\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 새로운 접근 방식 - LIFO(Last in First out)"
      ],
      "metadata": {
        "id": "VMsi4N3SsA-F"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* 이 접근 방식의 아이디어\n",
        "  * 사용자는 항상 문맥을 가지고 대화 시작\n",
        "  * 문맥은 변화고, 대화도 변한다.\n",
        "  * 사용자는 최근 2-5개 프롬프트에 문맥을 포함시킬 가능성이 매우 크다.\n",
        "* 히스토리를 저장할 텍스트 파일을 만들고, 구분자로 프롬프트와 답변을 저장한다.\n"
      ],
      "metadata": {
        "id": "1_wpAj3Ks1QT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from openai import OpenAI\n",
        "import os\n",
        "\n",
        "def init_api():\n",
        "    with open(\"chatgpt.env\") as env:\n",
        "       for line in env:\n",
        "           key, value = line.strip().split(\"=\")\n",
        "           os.environ[key] = value\n",
        "\n",
        "def save_history_to_file(history):\n",
        "    with open(\"history.txt\", \"w+\") as f:\n",
        "        f.write(history)\n",
        "\n",
        "def load_history_from_file():\n",
        "    with open(\"history.txt\", \"r\") as f:\n",
        "        return f.read()\n",
        "\n",
        "def get_relevant_history(history):\n",
        "    history_list = history.split(separator)\n",
        "    if len(history_list) > 2:\n",
        "        return separator.join(history_list[-2:])\n",
        "    else:\n",
        "        return history\n",
        "\n",
        "init_api()\n",
        "\n",
        "client = OpenAI(api_key  = os.environ.get(\"API_KEY\"),\n",
        "                organization  = os.environ.get(\"ORG_ID\"))"
      ],
      "metadata": {
        "id": "btMIWLLtVSDB"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "initial_prompt = \"\"\"\n",
        "You: 안녕!\n",
        "AI: 어떻게 잘 지냈니?\n",
        "You: {}\n",
        "AI:\n",
        "\"\"\"\n",
        "\n",
        "history = \"\"\n",
        "relevant_history = \"\"\n",
        "separator = \"#####\"\n",
        "save_history_to_file(history)\n",
        "\n",
        "while True :\n",
        "    prompt = input(\"You(q:quit): \")\n",
        "    if prompt=='q':\n",
        "        break\n",
        "    relevant_history = get_relevant_history(load_history_from_file())\n",
        "    next = client.completions.create(\n",
        "        model = \"gpt-3.5-turbo-instruct\",\n",
        "        prompt = initial_prompt.format(relevant_history + prompt),\n",
        "        temperature = 1,\n",
        "        max_tokens = 100,\n",
        "        stop = [\" You:\", \" AI:\"],\n",
        "    )\n",
        "    next_text = next.choices[0].text\n",
        "    history += \"\\nYou: \" + prompt + \"\\nAI: \" + next_text + \"\\n\" + separator\n",
        "    save_history_to_file(history)\n",
        "    print(\"AI: \" + next_text)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9RKuV8ibse__",
        "outputId": "6497e75f-c09e-4cfa-b6e9-e5bb7d7e5351"
      },
      "execution_count": 14,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "You(q:quit): 안녕\n",
            "AI: 안녕하세요?\n",
            "You(q:quit): ‘오늘의 단어장’에 이 단어 넣어주렴. ‘banana’ – 나중에 물어보면 알려주렴. \n",
            "AI: 오늘 배운 단어는 banana입니다. 나중에 물어보시면 더 자세히 알려드리겠습니다.\n",
            "You(q:quit): ‘오늘의 단어장’ 들어있는 단어는 뭐였지? \n",
            "AI: \n",
            "오늘 배운 단어는 banana입니다.\n",
            "You(q:quit): ‘오늘의 단어장’에 이 단어 넣어주렴. ‘apple’ – 나중에 물어보면 알려주렴. \n",
            "AI: 내일 배울 단어로 apple을 넣어놨어. 나중에 물어보면 알려줄게.\n",
            "You(q:quit): ‘오늘의 단어장’에 이 단어 넣어주렴. ‘orange’ – 나중에 물어보면 알려주렴. \n",
            "AI: \n",
            "네, 단어장에 orange 단어를 저장했어요. 나중에 물어보면 알려줄게요.\n",
            "You(q:quit): ‘오늘의 단어장’에 기억해 둔 단어를 알려주렴.\n",
            "AI: 저는 지금까지 orange 라는 단어를 기억하고 있어요. 다른 단어도 물어보세요!\n",
            "You(q:quit): q\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 선택적인 문맥 - LIFO의 한계의 해결 제안"
      ],
      "metadata": {
        "id": "mC_cdgFSjIWV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* 초기 프롬프트가 텍스트 파일에 저장\n",
        "* 사용자가 프롬프트에 입력\n",
        "* 모든 상호 작용에 대한 임베딩 생성\n",
        "* 임베딩과 코사인 유사도를 활용\n",
        "* 가장 높은 n개의 내용을 사용자에게 프롬프트와 함께 보내기"
      ],
      "metadata": {
        "id": "mbnOYuzvVkte"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 사전 다운로드 및 설치"
      ],
      "metadata": {
        "id": "0eGi8B9ecPuT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install spaCy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LEs6p8q04mE_",
        "outputId": "d77a8e6f-3078-49c6-c70b-daccba6edae6"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: spaCy in /usr/local/lib/python3.10/dist-packages (3.6.1)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spaCy) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spaCy) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spaCy) (1.0.10)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spaCy) (2.0.8)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spaCy) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.2.0,>=8.1.8 in /usr/local/lib/python3.10/dist-packages (from spaCy) (8.1.12)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spaCy) (1.1.2)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spaCy) (2.4.8)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spaCy) (2.0.10)\n",
            "Requirement already satisfied: typer<0.10.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spaCy) (0.9.0)\n",
            "Requirement already satisfied: pathy>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from spaCy) (0.10.3)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from spaCy) (6.4.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spaCy) (4.66.1)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.10/dist-packages (from spaCy) (1.23.5)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spaCy) (2.31.0)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spaCy) (1.10.13)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spaCy) (3.1.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spaCy) (67.7.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spaCy) (23.2)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spaCy) (3.3.0)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spaCy) (4.5.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spaCy) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spaCy) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spaCy) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spaCy) (2023.11.17)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spaCy) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spaCy) (0.1.4)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer<0.10.0,>=0.3.0->spaCy) (8.1.7)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spaCy) (2.1.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m spacy download en_core_web_md"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ieA9es5kvmIS",
        "outputId": "17ec8e3b-75be-4c35-9694-a1d0e22980d6"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-12-12 07:17:00.960138: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2023-12-12 07:17:00.960219: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2023-12-12 07:17:00.960269: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2023-12-12 07:17:02.326726: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "Collecting en-core-web-md==3.6.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_md-3.6.0/en_core_web_md-3.6.0-py3-none-any.whl (42.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.8/42.8 MB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: spacy<3.7.0,>=3.6.0 in /usr/local/lib/python3.10/dist-packages (from en-core-web-md==3.6.0) (3.6.1)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (1.0.10)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (2.0.8)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.2.0,>=8.1.8 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (8.1.12)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (1.1.2)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (2.4.8)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (2.0.10)\n",
            "Requirement already satisfied: typer<0.10.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (0.9.0)\n",
            "Requirement already satisfied: pathy>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (0.10.3)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (6.4.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (4.66.1)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (1.23.5)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (2.31.0)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (1.10.13)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (3.1.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (67.7.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (23.2)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (3.3.0)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (4.5.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (2023.11.17)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (0.1.4)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer<0.10.0,>=0.3.0->spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (8.1.7)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (2.1.3)\n",
            "Installing collected packages: en-core-web-md\n",
            "Successfully installed en-core-web-md-3.6.0\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_md')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 모든 코드를 합친 코드"
      ],
      "metadata": {
        "id": "ynkpOdbnmSpx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "import os\n",
        "import spacy\n",
        "import numpy as np\n",
        "from openai import OpenAI\n",
        "\n",
        "# 사전 학습된 spaCy 모델을 로드합니다.\n",
        "nlp = spacy.load('en_core_web_md')\n",
        "\n",
        "def init_api():\n",
        "    with open(\"chatgpt.env\") as env:\n",
        "       for line in env:\n",
        "           key, value = line.strip().split(\"=\")\n",
        "           os.environ[key] = value\n",
        "\n",
        "def save_history_to_file(history):\n",
        "    \"\"\" 대화 기록을 파일에 저장합니다. \"\"\"\n",
        "    with open(\"history.txt\", \"w+\") as f:\n",
        "        f.write(history)\n",
        "\n",
        "def load_history_from_file():\n",
        "    \"\"\" 파일로부터 모든 대화 기록을 불러옵니다. \"\"\"\n",
        "    with open(\"history.txt\", \"r\") as f:\n",
        "        return f.read()\n",
        "\n",
        "def cos_sim(a, b):\n",
        "    \"\"\" 두 문자열 사이의 코사인 유사도를 계산합니다.\n",
        "    사용자 입력과 기록된 대화 세그먼트 사이의 유사성 비교에 사용됩니다.\n",
        "    \"\"\"\n",
        "    a = nlp(a)\n",
        "    a_without_stopwords = nlp(' '.join([t.text for t in a if not t.is_stop]))\n",
        "    b = nlp(b)\n",
        "    b_without_stopwords = nlp(' '.join([t.text for t in b if not t.is_stop]))\n",
        "    return a_without_stopwords.similarity(b_without_stopwords)\n",
        "\n",
        "def sort_history(history, user_input):\n",
        "    \"\"\"\n",
        "    사용자 입력과 대화 기록 세그먼트 사이의 코사인 유사도에 기반하여 대화 기록을\n",
        "    정렬합니다. History는 세팅자(separator)로 구분된 세그먼트들의 문자열입니다.\n",
        "    \"\"\"\n",
        "    segments = history.split(separator)\n",
        "    similarities = []\n",
        "    for segment in segments:\n",
        "        # 사용자 입력과 세그먼트 간의 코사인 유사도를 얻습니다.\n",
        "        similarity = cos_sim(user_input, segment)\n",
        "        similarities.append(similarity)\n",
        "\n",
        "    sorted_similarities = np.argsort(similarities)\n",
        "    sorted_history = \"\"\n",
        "    for i in range(1, len(segments)):\n",
        "        sorted_history += segments[sorted_similarities[i]] + separator\n",
        "    save_history_to_file(sorted_history)\n",
        "\n",
        "def get_latest_n_from_history(history, n):\n",
        "    \"\"\"\n",
        "    대화 기록에서 최근 n개의 세그먼트를 가져옵니다.\n",
        "    History는 세팅자(separator)로 구분된 세그먼트들의 문자열입니다.\n",
        "    \"\"\"\n",
        "    segments = history.split(separator)\n",
        "    return separator.join(segments[-n:])\n",
        "\n",
        "init_api()\n",
        "client = OpenAI(api_key  = os.environ.get(\"API_KEY\"),\n",
        "                organization  = os.environ.get(\"ORG_ID\"))\n",
        "\n",
        "initial_prompt_1 = \"\"\"\n",
        "You: 안녕하세요!\n",
        "AI: 안녕하세요!\n",
        "#####\n",
        "You: 어떻게 지내세요?\n",
        "AI: 저는 잘 지내고 있어요, 감사합니다.\n",
        "#####\n",
        "You: 자동차에 대해 알고 있나요?\n",
        "AI: 네, 저는 자동차에 대해 어느 정도 알고 있습니다.\n",
        "#####\n",
        "You: 피자 먹나요?\n",
        "AI: 저는 피자를 먹지 않습니다. 저는 먹을 수 없는 AI입니다.\n",
        "#####\n",
        "You: 달에 가 본 적 있나요?\n",
        "AI: 저는 달에 가 본 적이 없습니다. 당신은 어떠세요?\n",
        "#####\n",
        "You: 당신의 이름은 무엇인가요?\n",
        "AI: 제 이름은 픽셀입니다. 당신의 이름은 무엇인가요?\n",
        "#####\n",
        "You: 가장 좋아하는 영화는 무엇인가요?\n",
        "AI: 제가 가장 좋아하는 영화는 '매트릭스'입니다. Follow the white rabbit :)\n",
        "#####\"\"\"\n",
        "\n",
        "initial_prompt_2 = \"\"\"You: {}\n",
        "AI: \"\"\"\n",
        "\n",
        "initial_prompt = initial_prompt_1 + initial_prompt_2\n",
        "separator = \"#####\"\n",
        "\n",
        "save_history_to_file(initial_prompt_1)\n",
        "\n",
        "while True :\n",
        "    prompt = input(\"You(q:quit): \")\n",
        "    if prompt=='q':\n",
        "        break\n",
        "    sort_history(load_history_from_file(), prompt)\n",
        "    history = load_history_from_file()\n",
        "    best_history = get_latest_n_from_history(history, 5)\n",
        "    full_user_prompt = initial_prompt_2.format(prompt)\n",
        "    full_prompt = best_history + \"\\n\" + full_user_prompt\n",
        "\n",
        "    next = client.completions.create(\n",
        "        model = \"gpt-3.5-turbo-instruct\",\n",
        "        prompt = full_prompt,\n",
        "        temperature = 1,\n",
        "        max_tokens = 100,\n",
        "        stop = [\" You:\", \" AI:\"],\n",
        "    )\n",
        "    response_text = next.choices[0].text.strip()\n",
        "    history += \"\\n\" + full_user_prompt + response_text + \"\\n\" + separator + \"\\n\"\n",
        "    save_history_to_file(history)\n",
        "    print(\"AI: \" + response_text)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tvaLFQ9BuFMO",
        "outputId": "dc9c3992-2cc0-4a5f-a4c0-be177023ced4"
      },
      "execution_count": 21,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "You(q:quit): 안녕\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-21-f5b51077c374>:34: UserWarning: [W008] Evaluating Doc.similarity based on empty vectors.\n",
            "  return a_without_stopwords.similarity(b_without_stopwords)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "AI: 안녕하세요? 전 누구예요?\n",
            "You(q:quit): 너는 무엇이 가능하니?\n",
            "AI: 저는 다양한 질문에 대답할 수 있고 언어 모델 기반으로 대화를 진행할 수 있습니다. 어떤 말씀이든 궁금하신 내용을 물어보세요.\n",
            "You(q:quit): 달에 가 본 적이 있니?\n",
            "AI: 제 의견은 당신은 로봇 인간 일수도 있습니다. 당신이 야외 활동을 좋아하는 사람이라면 아마 달을 방문한 적이 있을 수도 있습니다. 당신의 인생에 대해 더 알 수 있을까요?\n",
            "You(q:quit): 피자 먹을 수 있니?\n",
            "AI: 저는 로봇이기 때문에 먹을 수는 없지만, 사실상 반응해드릴 수 없는 맛을 느낄 수 있을 것 같습니다. 당신은 어떤 종류의 피자를 선호하나요?\n",
            "You(q:quit): 자동차에 대해 알고 있니?\n",
            "AI: 저는 자동차에 대해 많은 정보를 가지고 있습니다. 자동차를 이용하는 많은 사람들이 있기 때문에 자동차에 대해 아는 것이 중요합니다.\n",
            "You(q:quit): q\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Tz81N_yxurZc"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}